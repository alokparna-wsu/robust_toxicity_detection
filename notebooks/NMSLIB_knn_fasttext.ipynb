{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ft_compiled_path = \"../data/jigsaw/ft_compiled.npy\" # Embeddings generated from the vocabulary\n",
    "data_vocab_path = \"../data/jigsaw/data_vocab.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_embeds = np.load(ft_compiled_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "vocab=pickle.load(open(data_vocab_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305140, 30522)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_vocab_toks = bert_tokenizer.vocab.keys()\n",
    "vocab_toks = set( [w for idx, w in vocab.get_index_to_token_vocabulary().items() ])\n",
    "len(vocab_toks), len(bert_vocab_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are BERT vocabulary word IDs in the *MAIN vocabulary!*, not IDs in the BERT vocab.\n",
    "bert_vocab_ids = []\n",
    "\n",
    "for tok in bert_vocab_toks:\n",
    "    tok_id = vocab.get_token_index(tok)\n",
    "    if tok_id > 1:\n",
    "        bert_vocab_ids.append(tok_id)\n",
    "        \n",
    "bert_vocab_ids = np.array(bert_vocab_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22778, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_embeds[bert_vocab_ids].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index-time parameters {'M': 25, 'indexThreadQty': 0, 'efConstruction': 200, 'post': 0}\n"
     ]
    }
   ],
   "source": [
    "import nmslib, time\n",
    "\n",
    "M = 25\n",
    "efC = 200\n",
    "\n",
    "num_threads = 0\n",
    "index_time_params = {'M': M, 'indexThreadQty': num_threads, 'efConstruction': efC, 'post' : 0}\n",
    "print('Index-time parameters', index_time_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22778"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Space name should correspond to the space name \n",
    "# used for brute-force search\n",
    "space_name='cosinesimil'\n",
    "\n",
    "\n",
    "# Intitialize the library, specify the space, the type of the vector and add data points \n",
    "index = nmslib.init(method='hnsw', space=space_name, data_type=nmslib.DataType.DENSE_VECTOR) \n",
    "index.addDataPointBatch(fasttext_embeds[bert_vocab_ids], bert_vocab_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index-time parameters {'M': 25, 'indexThreadQty': 0, 'efConstruction': 200}\n",
      "Indexing time = 5.127838\n"
     ]
    }
   ],
   "source": [
    "# Create an index\n",
    "start = time.time()\n",
    "index_time_params = {'M': M, 'indexThreadQty': num_threads, 'efConstruction': efC}\n",
    "index.createIndex(index_time_params) \n",
    "end = time.time() \n",
    "print('Index-time parameters', index_time_params)\n",
    "print('Indexing time = %f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting query-time parameters {'efSearch': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Setting query-time parameters\n",
    "efS = 1000\n",
    "K=10\n",
    "query_time_params = {'efSearch': efS}\n",
    "print('Setting query-time parameters', query_time_params)\n",
    "index.setQueryTimeParams(query_time_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 300), 15741)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_id = vocab.get_token_index('doin')\n",
    "query_arr = [fasttext_embeds[tok_id]]\n",
    "query_matrix = np.array(query_arr)\n",
    "K=10\n",
    "query_matrix.shape, tok_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN time total=0.006099 (sec), per query=0.006099 (sec), per query adjusted for thread number=0.000000 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Querying\n",
    "query_qty = query_matrix.shape[0]\n",
    "start = time.time() \n",
    "nbrs = index.knnQueryBatch(query_matrix, k = K, num_threads = num_threads)\n",
    "end = time.time() \n",
    "print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' % \n",
    "      (end-start, float(end-start)/query_qty, num_threads*float(end-start)/query_qty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15741, 28278,  8782, 26640, 30965, 15506,  2943,  2653, 23717,\n",
       "         6678], dtype=int32),\n",
       " array([1.7881393e-07, 3.3468032e-01, 3.4271854e-01, 3.4451097e-01,\n",
       "        3.5699421e-01, 3.6550194e-01, 3.8245523e-01, 3.8343334e-01,\n",
       "        4.0046120e-01, 4.2676270e-01], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs[0][0], nbrs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doin\n",
      "somethin\n",
      "gonna\n",
      "nothin\n",
      "gotta\n",
      "goin\n",
      "alright\n",
      "wanna\n",
      "boogie\n",
      "daddy\n"
     ]
    }
   ],
   "source": [
    "for bert_tok_id in nbrs[0][0]:\n",
    "    print(vocab.get_token_from_index(bert_tok_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
