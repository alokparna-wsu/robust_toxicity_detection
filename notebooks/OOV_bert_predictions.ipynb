{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForMaskedLM\n",
    "\n",
    "bert_model_mlm = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "#bert_model_mlm.cuda()\n",
    "#bert_tokenizer.cuda()\n",
    "\n",
    "bert_id2tok = dict()\n",
    "for tok, tok_id in bert_tokenizer.vocab.items():\n",
    "    bert_id2tok[tok_id] = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "\n",
    "_spacy_tok = SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words\n",
    "\n",
    "def tokenizer(s: str):\n",
    "    s = s.lower()\n",
    "    return [w.text for w in _spacy_tok(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'doingg' in bert_tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns arrays of arrays!\n",
    "# Each array element is a tuple: \n",
    "# position of OOV word (with respect to the original tokenizer), sent for BERT tokenizer\n",
    "def get_bert_masked_inputs(tokenizer, bert_tokenizer, orig_text):\n",
    "    toks = tokenizer(orig_text)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    oov_pos = []\n",
    "    bert_vocab = bert_tokenizer.vocab\n",
    "    \n",
    "    for i in range(len(toks)):\n",
    "        if toks[i] not in bert_vocab:\n",
    "            oov_pos.append(i)\n",
    "            \n",
    "\n",
    "    for pos in oov_pos:\n",
    "        res.append( (pos, '[CLS] %s [MASK] %s [SEP]' % (' '.join(toks[0:pos]), ' '.join(toks[pos+1:])) ) )\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, '[CLS] what the [MASK] are you doingg here ? [SEP]'),\n",
       " (5, '[CLS] what the fcuk are you [MASK] here ? [SEP]')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bert_masked_inputs(tokenizer, bert_tokenizer, 'What the fcuk are you doingg here?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'what', 'the', '[MASK]', 'are', 'you', 'doing', 'here', '?', '[SEP]']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = bert_tokenizer.tokenize('[CLS] what the [MASK] are you doing here ? [SEP]')\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_bert_top_preds(tokenizer, bert_tokenizer, sent, k):\n",
    "    res = []\n",
    "    for pos, text in get_bert_masked_inputs(tokenizer, bert_tokenizer, sent):\n",
    "        # To accurately get what is the position of [MASK] according\n",
    "        # to BERT tokenizer, we need to re-tokenize the sentence using\n",
    "        # the BERT tokenizer\n",
    "        toks = bert_tokenizer.tokenize(text)\n",
    "        tok_ids = torch.LongTensor(bert_tokenizer.convert_tokens_to_ids(toks)).unsqueeze(0)\n",
    "        pos_bert = None\n",
    "        for i in range(len(toks)):\n",
    "            if toks[i] == '[MASK]':\n",
    "                pos_bert = i\n",
    "                break\n",
    "        assert(pos_bert is not None)\n",
    "        print(pos, text)\n",
    "        tok_ids = torch.LongTensor(bert_tokenizer.convert_tokens_to_ids(toks)).unsqueeze(0)\n",
    "        seg_ids = torch.zeros(tok_ids.shape[1], dtype=torch.int64).unsqueeze(0)\n",
    "        preds=torch.topk(bert_model_mlm(tok_ids, seg_ids), k=k,dim=2)[1].squeeze().numpy()\n",
    "        res.append( (pos, bert_tokenizer.convert_ids_to_tokens(preds[pos_bert]) ) )\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [CLS] what the [MASK] are you doingg here ? [SEP]\n",
      "5 [CLS] what the fcuk are you [MASK] here ? [SEP]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, ['hell', 'fuck', 'heck', 'devil', '...']),\n",
       " (5, ['doing', 'doin', 'saying', 'thinking', 'wearing'])]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bert_top_preds(tokenizer, bert_tokenizer, 'What the fcuk are you doingg here?', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
