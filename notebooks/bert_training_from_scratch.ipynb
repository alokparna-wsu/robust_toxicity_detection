{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for seamlessly running on colab\n",
    "import os\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.environ[\"IS_COLAB\"] = \"True\"\n",
    "except ImportError:\n",
    "    os.environ[\"IS_COLAB\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ \"$IS_COLAB\" = \"True\" ]; then\n",
    "    pip install git+https://github.com/facebookresearch/fastText.git\n",
    "    pip install torch\n",
    "    pip install torchvision\n",
    "    pip install allennlp\n",
    "    pip install dnspython\n",
    "    pip install jupyter_slack\n",
    "    pip install git+https://github.com/keitakurita/Better_LSTM_PyTorch.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from overrides import overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "import functools\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "def get_ref_free_exc_info():\n",
    "    \"Free traceback from references to locals/globals to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n",
    "    type, val, tb = sys.exc_info()\n",
    "    traceback.clear_frames(tb)\n",
    "    return (type, val, tb)\n",
    "\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = get_ref_free_exc_info() # must!\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper\n",
    "\n",
    "def ifnone(a: Any, alt: Any): return alt if a is None else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for papermill\n",
    "testing = True\n",
    "debugging = True\n",
    "seed = 1\n",
    "char_encoder = \"cnn\"\n",
    "computational_batch_size = 64\n",
    "batch_size = 64\n",
    "loss = \"is\"\n",
    "lr = 4e-3\n",
    "lr_schedule = \"slanted_triangular\"\n",
    "epochs = 6 if not testing else 1\n",
    "hidden_sz = 128\n",
    "dataset = \"jigsaw\"\n",
    "n_classes = 6\n",
    "max_seq_len = 128\n",
    "download_data = False\n",
    "ft_model_path = \"../data/jigsaw/ft_model.txt\"\n",
    "max_vocab_size = 40000\n",
    "dropouti = 0.2\n",
    "dropoutw = 0.0\n",
    "dropoute = 0.2\n",
    "dropoutr = 0.3 # TODO: Implement\n",
    "val_ratio = 0.0\n",
    "use_augmented = False\n",
    "freeze_embeddings = True\n",
    "mixup_ratio = 0.0\n",
    "discrete_mixup_ratio = 0.0\n",
    "attention_bias = True\n",
    "weight_decay = 0.\n",
    "bias_init = True\n",
    "neg_splits = 1\n",
    "num_layers = 2\n",
    "rnn_type = \"lstm\"\n",
    "pooling_type = \"augmented_multipool\" # attention or multipool or augmented_multipool\n",
    "model_type = \"standard\"\n",
    "use_word_level_features = True\n",
    "use_sentence_level_features = True\n",
    "bucket = True\n",
    "compute_thres_on_test = True\n",
    "find_lr = False\n",
    "permute_sentences = False\n",
    "run_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can we make this play better with papermill?\n",
    "config = Config(\n",
    "    testing=testing,\n",
    "    debugging=debugging,\n",
    "    seed=seed,\n",
    "    char_encoder=char_encoder,\n",
    "    computational_batch_size=computational_batch_size,\n",
    "    batch_size=batch_size,\n",
    "    loss=loss,\n",
    "    lr=lr,\n",
    "    lr_schedule=lr_schedule,\n",
    "    epochs=epochs,\n",
    "    hidden_sz=hidden_sz,\n",
    "    dataset=dataset,\n",
    "    n_classes=n_classes,\n",
    "    max_seq_len=max_seq_len, # necessary to limit memory usage\n",
    "    ft_model_path=ft_model_path,\n",
    "    max_vocab_size=max_vocab_size,\n",
    "    dropouti=dropouti,\n",
    "    dropoutw=dropoutw,\n",
    "    dropoute=dropoute,\n",
    "    dropoutr=dropoutr,\n",
    "    val_ratio=val_ratio,\n",
    "    use_augmented=use_augmented,\n",
    "    freeze_embeddings=freeze_embeddings,\n",
    "    attention_bias=attention_bias,\n",
    "    weight_decay=weight_decay,\n",
    "    bias_init=bias_init,\n",
    "    neg_splits=neg_splits,\n",
    "    num_layers=num_layers,\n",
    "    rnn_type=rnn_type,\n",
    "    pooling_type=pooling_type,\n",
    "    model_type=model_type,\n",
    "    use_word_level_features=use_word_level_features,\n",
    "    use_sentence_level_features=use_sentence_level_features,\n",
    "    mixup_ratio=mixup_ratio,\n",
    "    discrete_mixup_ratio=discrete_mixup_ratio,\n",
    "    bucket=bucket,\n",
    "    compute_thres_on_test=compute_thres_on_test,\n",
    "    permute_sentences=permute_sentences,\n",
    "    find_lr=find_lr,\n",
    "    run_id=run_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "T = TypeVar(\"T\")\n",
    "TensorDict = Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]  # pylint: disable=invalid-name\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ[\"IS_COLAB\"] != \"True\":\n",
    "    DATA_ROOT = Path(\"../data\") / config.dataset\n",
    "else:\n",
    "    DATA_ROOT = Path(\"./gdrive/My Drive/Colab_Workspace/Colab Notebooks/data\") / config.dataset\n",
    "    config.ft_model_path = str(DATA_ROOT / \"ft_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "if download_data:\n",
    "    if config.val_ratio > 0.0:\n",
    "        fnames = [\"train_wo_val.csv\", \"test_proced.csv\", \"val.csv\", \"ft_model.txt\"]\n",
    "    else:\n",
    "        fnames = [\"train.csv\", \"test_proced.csv\", \"ft_model.txt\"]\n",
    "    if config.use_augmented or config.discrete_mixup_ratio > 0.0: fnames.append(\"train_extra.csv\")\n",
    "    for fname in fnames:\n",
    "        if not (DATA_ROOT / fname).exists():\n",
    "            print(subprocess.Popen([f\"aws s3 cp s3://nnfornlp/raw_data/jigsaw/{fname} {str(DATA_ROOT)}\"],\n",
    "                                   shell=True, stdout=subprocess.PIPE).stdout.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import (TextField, SequenceLabelField, LabelField, \n",
    "                                  MetadataField, ArrayField)\n",
    "\n",
    "class JigsawLMDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer]=None, # TODO: Handle mapping from BERT\n",
    "                 output_token_indexers: Dict[str, TokenIndexer]=None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers\n",
    "        self.output_token_indexers = output_token_indexers or token_indexers\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def _clean(self, x: str) -> str:\n",
    "        \"\"\"\n",
    "        Maps a word to its desired output. Will leave as identity for now.\n",
    "        In the future, will change to denoising operation.\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[str]) -> Instance:\n",
    "        sentence_field = TextField([Token(x) for x in tokens],\n",
    "                                   self.token_indexers)\n",
    "        fields = {\"input\": sentence_field}\n",
    "        output_sentence_field = TextField([Token(self._clean(x)) for x in tokens],\n",
    "                                          self.output_token_indexers)\n",
    "        fields[\"output\"] = output_sentence_field\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                self.tokenizer(row[\"comment_text\"]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "\n",
    "if config.char_encoder == \"cnn\":\n",
    "    token_indexer = ELMoTokenCharactersIndexer()\n",
    "else:\n",
    "    token_indexer = SingleIdTokenIndexer(lowercase_tokens=True) # Temporary\n",
    "\n",
    "_spacy_tok = SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words\n",
    "\n",
    "def tokenizer(x: str):\n",
    "        return [\"[CLS]\"] + [w.text for w in\n",
    "                _spacy_tok(x)[:config.max_seq_len - 2]] + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:07, 129.51it/s]\n",
      "1000it [00:05, 170.73it/s]\n",
      "1000it [00:09, 100.95it/s]\n"
     ]
    }
   ],
   "source": [
    "if not isinstance(token_indexer, SingleIdTokenIndexer):\n",
    "    output_token_indexer = SingleIdTokenIndexer(lowercase_tokens=False)\n",
    "else:\n",
    "    output_token_indexer = token_indexer\n",
    "reader = JigsawLMDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer},\n",
    "    output_token_indexers={\"words\": output_token_indexer}\n",
    ")\n",
    "train_ds, val_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train_wo_val.csv\",\n",
    "                                                                          \"val.csv\",\n",
    "                                                                          \"test_proced.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [[CLS],\n",
       "  How,\n",
       "  can,\n",
       "  my,\n",
       "  comment,\n",
       "  on,\n",
       "  my,\n",
       "  own,\n",
       "  talk,\n",
       "  page,\n",
       "  WP,\n",
       "  :,\n",
       "  DISRUPT,\n",
       "  wikipedia,\n",
       "  ?,\n",
       "  [SEP]],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x12b37db38>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[2].fields[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [[CLS],\n",
       "  How,\n",
       "  can,\n",
       "  my,\n",
       "  comment,\n",
       "  on,\n",
       "  my,\n",
       "  own,\n",
       "  talk,\n",
       "  page,\n",
       "  WP,\n",
       "  :,\n",
       "  DISRUPT,\n",
       "  wikipedia,\n",
       "  ?,\n",
       "  [SEP]],\n",
       " '_token_indexers': {'words': <allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer at 0x12b37da58>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[2].fields[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 5661.09it/s]\n"
     ]
    }
   ],
   "source": [
    "full_ds = train_ds + test_ds + val_ds\n",
    "vocab = Vocabulary.from_instances(full_ds, tokens_to_add={\"tokens\": [\"[MASK]\"]},\n",
    "                                  max_vocab_size=config.max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17977"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set(\"vocab_sz\", vocab.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement fast sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\" and config.loss == \"is\":\n",
    "    freqs = np.zeros(vocab.get_vocab_size())\n",
    "    for w, c in vocab._retained_counter[\"tokens\"].items():\n",
    "        freqs[vocab.get_token_index(w)] = c\n",
    "    freqs /= freqs.sum()\n",
    "    freqs **= 2 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator, DataIterator\n",
    "iterator = BucketIterator(\n",
    "        batch_size=config.batch_size, \n",
    "        biggest_batch_first=config.testing,\n",
    "        sorting_keys=[(\"input\", \"num_tokens\")],\n",
    ")\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 128, 50])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterator(train_ds))[\"input\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'tokens': tensor([[[259,  92,  68,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  74, 116,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259,  50,  52,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  92,  84,  ..., 261, 261, 261]],\n",
       "  \n",
       "          [[259,  92,  68,  ..., 261, 261, 261],\n",
       "           [259,  74, 117,  ..., 261, 261, 261],\n",
       "           [259, 116, 109,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259,  74, 103,  ..., 261, 261, 261],\n",
       "           [259, 115, 102,  ..., 261, 261, 261],\n",
       "           [259,  92,  84,  ..., 261, 261, 261]],\n",
       "  \n",
       "          [[259,  92,  68,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  81, 115,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259, 106, 111,  ..., 261, 261, 261],\n",
       "           [259,  99, 122,  ..., 261, 261, 261],\n",
       "           [259,  92,  84,  ..., 261, 261, 261]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[259,  92,  68,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  66, 118,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259,  98, 260,  ..., 261, 261, 261],\n",
       "           [259, 120, 106,  ..., 261, 261, 261],\n",
       "           [259,  92,  84,  ..., 261, 261, 261]],\n",
       "  \n",
       "          [[259,  92,  68,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  59, 260,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259, 102, 121,  ..., 261, 261, 261],\n",
       "           [259,  98, 117,  ..., 261, 261, 261],\n",
       "           [259,  92,  84,  ..., 261, 261, 261]],\n",
       "  \n",
       "          [[259,  92,  68,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  83, 102,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259, 103, 115,  ..., 261, 261, 261],\n",
       "           [259,  99, 115,  ..., 261, 261, 261],\n",
       "           [259,  92,  84,  ..., 261, 261, 261]]])},\n",
       " 'output': {'words': tensor([[   7,    5, 3528,  ..., 9010,    5,    8],\n",
       "          [   7,   64, 9698,  ...,   67,  333,    8],\n",
       "          [   7,    5, 3522,  ..., 3525,   50,    8],\n",
       "          ...,\n",
       "          [   7,    5,  892,  ...,   11, 1710,    8],\n",
       "          [   7,    5,   15,  ...,  907,   47,    8],\n",
       "          [   7,    5, 1223,  ...,   44, 5415,    8]])}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build word to indices mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17977/17977 [00:00<00:00, 42401.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Building character indexes] done in 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    from tqdm import tqdm\n",
    "    # TODO: Speed up\n",
    "    # TODO: Debug\n",
    "    # See allennlp/data/token_indexers/elmo_indexer.py\n",
    "    with timer(\"Building character indexes\"):\n",
    "        word_id_to_char_idxs = np.zeros((config.vocab_sz, 50))\n",
    "        freqs = []\n",
    "        for w, idx in tqdm(vocab.get_token_to_index_vocabulary().items()):\n",
    "            # TODO: Check for start/end of word symbols\n",
    "            if idx > 0: \n",
    "                word_id_to_char_idxs[idx, :] = 261\n",
    "                word_id_to_char_idxs[idx, 0] = 259\n",
    "                for i, c in enumerate(w.encode(\"utf-8\")):\n",
    "                    if i + 1 == 48: break\n",
    "                    word_id_to_char_idxs[idx, i+1] = int(c) + 1\n",
    "                word_id_to_char_idxs[idx, i+2] = 260\n",
    "        word_id_to_char_idxs = np.array(word_id_to_char_idxs)\n",
    "\n",
    "    word_id_to_char_idxs = torch.LongTensor(word_id_to_char_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    mask_char_ids = torch.ones(50, dtype=torch.int64) * 261\n",
    "    for i, c in enumerate(\"[MASK]\".encode(\"utf-8\")):\n",
    "        mask_char_ids[i+1] = int(c) + 1\n",
    "    mask_char_ids[i+2] = 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    print((batch[\"input\"][\"tokens\"][0] == word_id_to_char_idxs[batch[\"output\"][\"words\"][0]]).all().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 32,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 128,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 40000\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert.modeling import (BertConfig, BertForMaskedLM, \n",
    "                                              BertEncoder, BertPooler, BertOnlyMLMHead)\n",
    "\n",
    "bert_config = BertConfig(\n",
    "        config.max_vocab_size, hidden_size=32, num_attention_heads=4,\n",
    "        num_hidden_layers=4, intermediate_size=32 * 4,\n",
    ")\n",
    "\n",
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building token embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    from allennlp.modules.token_embedders.elmo_token_embedder import ElmoTokenEmbedder\n",
    "    from allennlp.modules.elmo import _ElmoCharacterEncoder\n",
    "\n",
    "    options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "    weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "    _inner_char_encoder = _ElmoCharacterEncoder(\n",
    "        options_file=options_file, \n",
    "        weight_file=weight_file,\n",
    "        requires_grad=True\n",
    "    )\n",
    "    class ElmoEncoder(nn.Module):\n",
    "        def __init__(self, _inner):\n",
    "            super().__init__()\n",
    "            self._inner = _inner\n",
    "        def forward(self, *args):\n",
    "            # TODO: Stop Elmo encoder from adding SoS and EoS tokens\n",
    "            return self._inner(*args)[\"token_embedding\"][:, 1:-1, :]\n",
    "        def get_output_dim(self):\n",
    "            return self._inner.get_output_dim()\n",
    "    char_encoder = ElmoEncoder(_inner_char_encoder)\n",
    "\n",
    "# char_encoder\n",
    "\n",
    "# sample_idxs = next(iterator(train_ds))[\"tokens\"][\"tokens\"]\n",
    "\n",
    "# char_encoder(sample_idxs)\n",
    "    config.set(\"embedding_sz\", char_encoder.get_output_dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of char-ngrams using fastText (too much memory consumption for now...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"boc\":\n",
    "    from fastText import load_model\n",
    "    from torch.nn.modules.sparse import EmbeddingBag\n",
    "    \n",
    "    # TODO: Reduce size of fasttext model binary\n",
    "    class FastTextEmbeddingBag(EmbeddingBag):\n",
    "        def __init__(self, model_path):\n",
    "            self.model = load_model(model_path)\n",
    "            input_matrix = self.model.get_input_matrix()\n",
    "            input_matrix_shape = input_matrix.shape\n",
    "            super().__init__(input_matrix_shape[0], input_matrix_shape[1])\n",
    "            self.weight.data.copy_(torch.FloatTensor(input_matrix))\n",
    "\n",
    "        def forward(self, words):\n",
    "            word_subinds = np.empty([0], dtype=np.int64)\n",
    "            word_offsets = [0]\n",
    "            for word in words:\n",
    "                _, subinds = self.model.get_subwords(word)\n",
    "                word_subinds = np.concatenate((word_subinds, subinds))\n",
    "                word_offsets.append(word_offsets[-1] + len(subinds))\n",
    "            word_offsets = word_offsets[:-1]\n",
    "            ind = torch.LongTensor(word_subinds)\n",
    "            offsets = torch.LongTensor(word_offsets)\n",
    "            return super().forward(ind, offsets)\n",
    "    \n",
    "    char_encoder = FastTextEmbeddingBag(str(DATA_ROOT / \"ft_model.bin\"))\n",
    "    config.set(\"embedding_sz\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple word-level embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"fasttext\":\n",
    "    from allennlp.modules import Embedding\n",
    "\n",
    "    ft_matrix = np.random.randn(bert_config.vocab_size, 300) * 0.3\n",
    "    char_encoder = Embedding(bert_config.vocab_size, 300, weight=torch.FloatTensor(ft_matrix))\n",
    "    config.set(\"embedding_sz\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(x):\n",
    "    x.requires_grad = False\n",
    "    if hasattr(x, \"parameters\"):\n",
    "        for p in x.parameters: freeze(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingWPositionEmbs(nn.Module):\n",
    "    \"\"\"Embeds, then maps the embeddings to the bert_hidden_sz for processing\"\"\"\n",
    "    def __init__(self, word_emb: nn.Module, \n",
    "                 embedding_dim,\n",
    "                 bert_hidden_sz, \n",
    "                 freeze_embeddings=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.word_emb = word_emb\n",
    "        if freeze_embeddings: freeze(self.word_emb)\n",
    "        self.position_embeddings = nn.Embedding(config.max_seq_len, \n",
    "                                                bert_hidden_sz)\n",
    "        self.linear = nn.Linear(embedding_dim, bert_hidden_sz,\n",
    "                                bias=False) # Transform dimensions\n",
    "        self.norm = LayerNorm(bert_hidden_sz)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "    \n",
    "    def get_word_embs(self, input_ids):\n",
    "        return self.linear(self.word_emb(input_ids))\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        # We won't be using token types since we won't be predicting the next sentence\n",
    "        bs, seq_length, *_ = input_ids.shape\n",
    "        position_ids = (torch.arange(seq_length, dtype=torch.long)\n",
    "                             .to(input_ids.device)\n",
    "                             .unsqueeze(0)\n",
    "                             .expand((bs, seq_length)))\n",
    "        word_embs = self.get_word_embs(input_ids)\n",
    "        position_embs = self.position_embeddings(position_ids)\n",
    "        return self.do(self.norm(word_embs + position_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embs = EmbeddingWPositionEmbs(\n",
    "    char_encoder,\n",
    "    config.embedding_sz,\n",
    "    bert_config.hidden_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingWPositionEmbs(\n",
       "  (word_emb): ElmoEncoder(\n",
       "    (_inner): _ElmoCharacterEncoder(\n",
       "      (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "      (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "      (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "      (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "      (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "      (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "      (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "      (_highways): Highway(\n",
       "        (_layers): ModuleList(\n",
       "          (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (position_embeddings): Embedding(128, 32)\n",
       "  (linear): Linear(in_features=128, out_features=32, bias=False)\n",
       "  (norm): LayerNorm()\n",
       "  (do): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encoder = BertEncoder(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, embeddings, encoder):\n",
    "        super().__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def forward(self, input_ids, \n",
    "                token_type_ids=None, \n",
    "                attention_mask=None):\n",
    "        if attention_mask is None:\n",
    "            if len(input_ids.shape) > 2:\n",
    "                attention_mask = torch.ones_like(input_ids[:, :, 0])\n",
    "            else:\n",
    "                attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            if len(input_ids.shape) > 2:\n",
    "                token_type_ids = torch.ones_like(input_ids[:, :, 0])\n",
    "            else:\n",
    "                token_type_ids = torch.ones_like(input_ids)\n",
    "        \n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids)\n",
    "        encoded_layers = self.encoder(embedding_output,\n",
    "                                      extended_attention_mask,\n",
    "                                      output_all_encoded_layers=True)\n",
    "        return encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMLMPooler(nn.Module):\n",
    "    def forward(self, x: List[torch.FloatTensor]) -> torch.FloatTensor:\n",
    "        return x[-1] # return final layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = CustomBert(sample_embs, bert_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "class BertCustomLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config, out_sz, vocab_sz, \n",
    "                 embedding, output_logits=True):\n",
    "        super().__init__()\n",
    "        # Projections\n",
    "        self.dense = nn.Linear(config.hidden_size, out_sz)\n",
    "        self.transform_act_fn = gelu\n",
    "        self.LayerNorm = LayerNorm(out_sz)\n",
    "        \n",
    "        # Predictions\n",
    "        self.output_logits = output_logits\n",
    "        if self.output_logits:\n",
    "            self.decoder = nn.Linear(out_sz, vocab_sz, \n",
    "                                     bias=False)\n",
    "            if embedding is not None:\n",
    "                self.decoder.weight = embedding\n",
    "            self.bias = nn.Parameter(torch.zeros(vocab_sz))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        if self.output_logits:\n",
    "            hidden_states = self.dense(hidden_states)\n",
    "            hidden_states = self.transform_act_fn(hidden_states)\n",
    "            preds = self.LayerNorm(hidden_states)\n",
    "            preds = self.decoder(preds) + self.bias\n",
    "        else:\n",
    "            preds = hidden_states\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logits = config.loss != \"is\"\n",
    "bert_mlm_head = BertCustomLMPredictionHead(config=bert_config, \n",
    "                                           out_sz=config.embedding_sz, \n",
    "                                           vocab_sz=config.vocab_sz,\n",
    "                                           embedding=(sample_embs.word_emb.weight \n",
    "                                                      if config.char_encoder == \"fasttext\" \n",
    "                                                      else None),\n",
    "                                           output_logits=output_logits,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = nn.Sequential(\n",
    "    bert_model,\n",
    "    BertMLMPooler(),\n",
    "    bert_mlm_head,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder != \"fasttext\":\n",
    "    from allennlp.modules import Embedding\n",
    "    output_embs = Embedding(config.vocab_sz, bert_config.hidden_size)\n",
    "else:\n",
    "    output_embs = sample_embs.get_word_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unigram_noise(freq):\n",
    "    \"\"\"build the unigram noise from a list of frequency\n",
    "    Parameters:\n",
    "        freq: a tensor of #occurrences of the corresponding index\n",
    "    Return:\n",
    "        unigram_noise: a torch.Tensor with size ntokens,\n",
    "        elements indicate the probability distribution\n",
    "    \"\"\"\n",
    "    total = freq.sum()\n",
    "    noise = freq / total\n",
    "    assert abs(noise.sum() - 1) < 0.001\n",
    "    return noise ** 0.75 # slight modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, preds, tgts, mask=None) -> torch.tensor:\n",
    "        if mask is None:\n",
    "            return self._loss(preds, tgts).mean()\n",
    "        else:\n",
    "            # Is this reshaping really necessary? Seems like there would be a more elegant solution\n",
    "            loss = self._loss(preds.view((-1, preds.size(-1))),\n",
    "                              tgts.view((-1, )))\n",
    "            n_elements = mask.sum()\n",
    "            return (loss * mask.view((-1, )).float()).sum() / n_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformSampler:\n",
    "    def __init__(self, min_, max_):\n",
    "        self.min_, self.max_ = min_, max_\n",
    "    \n",
    "    def sample(self, shape):\n",
    "        return torch.randint(low=self.min_,\n",
    "                             high=self.max_, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportanceSamplingLoss(nn.Module):\n",
    "    def __init__(self, embedding_generator,\n",
    "                 probs: np.ndarray, k=10):\n",
    "        super().__init__()\n",
    "        self.embedding_generator = embedding_generator\n",
    "        # TODO: Should this be according to the unigram probability?\n",
    "        # Or should it be uniform?\n",
    "        self.sampler = UniformSampler(1, vocab.get_vocab_size())\n",
    "#         self.sampler = Categorical(probs=probs)\n",
    "        # TODO: Compute samples in advance\n",
    "        self._loss_func = MaskedCrossEntropyLoss()\n",
    "        self.k = k\n",
    "    \n",
    "    def get_negative_samples(self, bs) -> torch.LongTensor:\n",
    "        neg = self.sampler.sample((bs, self.k, )) # TODO: Speed up??\n",
    "        return neg\n",
    "    \n",
    "    def get_embeddings(self, idxs: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Converts indexes into vectors\"\"\"\n",
    "        return self.embedding_generator(idxs) # TODO: Implement general case\n",
    "    \n",
    "    def forward(self, y: torch.LongTensor, tgt, mask=None):\n",
    "        \"\"\"\n",
    "        Expects input of shape\n",
    "        y: (batch * seq, feature_sz)\n",
    "        tgt: (batch * seq, )\n",
    "        \"\"\"\n",
    "        if len(y.shape) > 2:            \n",
    "            y = y.view((-1, y.size(-1))) # (batch * seq, feature_sz)\n",
    "            tgt = tgt.view((-1, )) # (batch * seq, s)\n",
    "        bs = y.size(0)\n",
    "        neg_samples = self.get_negative_samples(bs)\n",
    "        idxs = torch.cat([tgt.unsqueeze(1), neg_samples], dim=1)\n",
    "        # TODO: More efficien implementation?\n",
    "        # y: (batch * seq, feature_sz)\n",
    "        # embeddings: (batch * seq, feature_sz, k)\n",
    "        dot_prods = torch.einsum(\"bkf,bf->bk\", self.get_embeddings(idxs), y)\n",
    "        return self._loss_func(dot_prods, torch.zeros(bs, dtype=torch.int64),\n",
    "                               mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn((3, 7, bert_config.hidden_size)).view((-1, bert_config.hidden_size))\n",
    "tgt = torch.randint(100, (3, 7)).view((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorical(probs=torch.rand(100, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = cat.sample((y.size(0), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.cat([tgt.unsqueeze(1), neg_samples], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11, 32])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embs(idxs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 32])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4042, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = ImportanceSamplingLoss(\n",
    "    output_embs, probs=torch.rand(100),\n",
    ")\n",
    "loss(y, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(y.unsqueeze(1), loss.get_embeddings(idxs).transpose(1, 2)).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.get_embeddings(idxs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCorrection(nn.Module):\n",
    "    \"\"\"From the paper `Exploring the Limitations of Language Modeling`\"\"\"\n",
    "    def __init__(self, hidden_sz: int, bottleneck_sz: int=128):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(hidden_sz, bottleneck_sz)\n",
    "        \n",
    "    def forward(self, h: torch.FloatTensor, \n",
    "                corr: torch.FloatTensor):\n",
    "        x = self.l1(h)\n",
    "        return x @ corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different decoder (TODO: Enable sharing of parameters)\n",
    "# char_decoder = _ElmoCharacterEncoder(\n",
    "#     options_file=options_file, \n",
    "#     weight_file=weight_file,\n",
    "#     requires_grad=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masker(nn.Module):\n",
    "    def __init__(self, vocab: Vocabulary, \n",
    "                 noise_rate: float=0.15,\n",
    "                 mask_rate=0.8,\n",
    "                 replace_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.vocab_sz = vocab.get_vocab_size()\n",
    "        if config.char_encoder == \"cnn\":\n",
    "            self.mask_id = mask_char_ids.unsqueeze(0).unsqueeze(1)\n",
    "        else:\n",
    "            self.mask_id = vocab.get_token_index(\"[MASK]\")\n",
    "        self.noise_rate = noise_rate\n",
    "        self.mask_rate = mask_rate\n",
    "        self.replace_rate = replace_rate\n",
    "        \n",
    "    def create_mask(self, shape, ones_ratio, dtype=torch.uint8):\n",
    "        return (torch.ones(shape, dtype=dtype, \n",
    "                           requires_grad=False)\n",
    "                     .bernoulli(ones_ratio))\n",
    "\n",
    "    def get_random_input_ids(self, shape):\n",
    "        \"\"\"Returns randomly sampled \"\"\"\n",
    "        if config.char_encoder == \"cnn\":\n",
    "            rint = torch.randint(self.vocab_sz, shape)\n",
    "            return word_id_to_char_idxs[rint]\n",
    "        elif config.char_encoder == \"fasttext\":\n",
    "            return torch.randint(self.vocab_sz, shape)\n",
    "\n",
    "    def forward(self, x: torch.LongTensor) -> torch.LongTensor:\n",
    "        char_level = len(x.shape) > 2\n",
    "        if self.train and self.noise_rate > 0:\n",
    "            with torch.no_grad(): # no grads required here\n",
    "                mask_shape = x.shape[:-1] if char_level else x.shape\n",
    "                mask = self.create_mask(mask_shape, \n",
    "                                        self.noise_rate * self.mask_rate)\n",
    "                if config.char_encoder == \"cnn\":\n",
    "                    x = torch.where(mask.unsqueeze(2), self.mask_id, x)                \n",
    "                else:\n",
    "                    x = x.masked_fill(mask, self.mask_id)\n",
    "                \n",
    "                if self.replace_rate > 0.:\n",
    "                    # this is techinically incorrect, since we might overwrite the mask tokens\n",
    "                    # but I guess it will do for now\n",
    "                    mask = self.create_mask(mask_shape,\n",
    "                                            self.noise_rate * self.replace_rate)\n",
    "                    x = torch.where(mask.unsqueeze(2) if config.char_encoder == \"cnn\" else mask, \n",
    "                                    self.get_random_input_ids(mask_shape),\n",
    "                                    x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "\n",
    "class MaskedLM(Model):\n",
    "    def __init__(self, vocab: Vocabulary, model: nn.Module,\n",
    "                loss: nn.Module, noise_rate=0.8):\n",
    "        super().__init__(vocab)\n",
    "        self.masker = Masker(vocab, noise_rate=noise_rate)\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "    \n",
    "    @property\n",
    "    def outputs_logits(self) -> bool:\n",
    "        return self.model[-1].output_logits\n",
    "    \n",
    "    def forward(self, input: TensorDict, \n",
    "                output: TensorDict, **kwargs) -> TensorDict:\n",
    "        mask = get_text_field_mask(input)\n",
    "        x = self.masker(input[\"tokens\"])\n",
    "        tgt = output[\"words\"]\n",
    "        \n",
    "        logits = self.model(x)\n",
    "        out_dict = {\"loss\": self.loss(logits, tgt, mask=mask)}\n",
    "        out_dict[\"logits\"] = logits\n",
    "        if self.outputs_logits:\n",
    "            out_dict[\"accuracy\"] = self.accuracy(logits, tgt)\n",
    "        return out_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        if self.outputs_logits:\n",
    "            return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
    "        else:\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.loss == \"masked_crossentropy\":\n",
    "    loss = MaskedCrossEntropyLoss()\n",
    "elif config.loss == \"crossentropy\":\n",
    "    _loss = nn.CrossEntropyLoss()\n",
    "    def ce(y, t, mask=None): \n",
    "        return _loss(y.view((-1, y.size(-1))), t.view((-1, )))\n",
    "    loss = ce\n",
    "elif config.loss == \"is\":\n",
    "    # TODO: Implement masking\n",
    "    loss = ImportanceSamplingLoss(output_embs, None) # temporarily sample at random\n",
    "else:\n",
    "    raise ValueError(\"AAAAAAAAAAAAA\")\n",
    "masked_lm = MaskedLM(vocab, custom_model, loss, noise_rate=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = masked_lm.masker(batch[\"input\"][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = masked_lm.model[:2](tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5804,  0.7760, -1.8739,  ...,  1.9227,  0.7227,  0.1324],\n",
       "         [ 0.3603, -0.3518,  0.5121,  ..., -0.1061,  1.1555, -1.0039],\n",
       "         [-1.2652, -1.1676, -1.7268,  ...,  0.4276,  0.7936, -0.5868],\n",
       "         ...,\n",
       "         [-0.3311,  0.4366, -0.5052,  ...,  0.3579, -0.2515, -0.4568],\n",
       "         [ 0.2791,  0.7221, -1.7120,  ...,  0.4504,  0.3753, -1.3002],\n",
       "         [ 1.1276, -0.1795, -1.3316,  ...,  0.4769,  0.0311, -1.1109]],\n",
       "\n",
       "        [[-1.8727,  0.9486, -2.4024,  ...,  1.2721,  1.2755,  0.1641],\n",
       "         [-0.0389, -0.4296,  0.4552,  ...,  0.2502,  0.8206, -1.0632],\n",
       "         [-0.7303, -0.9013, -0.9299,  ...,  0.5584,  1.2745, -0.7620],\n",
       "         ...,\n",
       "         [-0.6082,  0.5045, -1.7468,  ...,  1.2611, -0.4222, -0.4912],\n",
       "         [ 0.5867,  0.8731, -1.3594,  ...,  0.8824,  1.8493, -1.1965],\n",
       "         [ 0.2679,  0.2569, -1.1916,  ...,  0.6775,  0.1391, -0.8199]],\n",
       "\n",
       "        [[-1.4472,  1.0144, -1.9252,  ...,  2.3477,  1.1999, -0.2477],\n",
       "         [ 0.1438, -0.3137,  0.5217,  ..., -0.0272,  0.7662, -1.1932],\n",
       "         [-0.9356, -0.9271, -0.9166,  ...,  0.5367,  1.0615, -1.2017],\n",
       "         ...,\n",
       "         [-0.7683,  0.5726, -0.7318,  ...,  1.4685, -0.7158,  0.0764],\n",
       "         [ 0.2705,  1.0022, -1.4917,  ...,  0.6646,  1.5993, -1.3566],\n",
       "         [ 0.4977,  0.1304, -1.1505,  ...,  0.7422,  0.2033, -1.1111]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.6577,  0.9544, -2.1424,  ...,  2.1238,  0.9263, -0.0293],\n",
       "         [-0.2187, -0.1886,  0.0907,  ...,  0.3346,  0.9378, -1.1442],\n",
       "         [-0.1288, -0.4161, -1.6377,  ...,  0.0870,  0.7573, -1.4749],\n",
       "         ...,\n",
       "         [-0.4910,  0.7181, -1.3422,  ...,  1.1879, -0.2907, -0.5513],\n",
       "         [-0.6495,  0.7249, -1.2720,  ...,  1.0576,  1.2781, -0.9256],\n",
       "         [ 0.7523,  0.1909, -1.3819,  ...,  0.5215,  0.0461, -1.4563]],\n",
       "\n",
       "        [[-1.5589,  0.9652, -2.0243,  ...,  1.8752,  1.1014,  0.3077],\n",
       "         [-0.0728,  0.0363,  0.1890,  ...,  0.0696,  1.1726, -0.9204],\n",
       "         [-0.6000, -0.5426, -1.5638,  ...,  0.3160,  0.7506, -0.9043],\n",
       "         ...,\n",
       "         [-0.1932,  0.2337, -1.1409,  ...,  1.2323, -0.1601, -0.6029],\n",
       "         [ 0.5266,  1.1477, -1.1567,  ...,  0.5830,  1.5202, -1.3806],\n",
       "         [-0.1277, -0.1671, -1.3583,  ...,  0.6845, -0.1811, -1.0193]],\n",
       "\n",
       "        [[-1.3792,  0.9834, -2.1462,  ...,  2.3539,  0.9531,  0.0422],\n",
       "         [-0.1993, -0.4514,  0.5747,  ...,  0.0254,  1.1546, -1.0678],\n",
       "         [-0.7605, -0.8715, -1.4006,  ...,  0.2954,  0.5497, -0.4620],\n",
       "         ...,\n",
       "         [-0.4317,  0.2376, -1.6393,  ...,  0.9963, -0.6953, -0.6126],\n",
       "         [ 0.4695,  0.6639, -1.2341,  ...,  1.2848,  1.6361, -1.4584],\n",
       "         [ 0.6991,  0.1452, -1.0277,  ...,  0.7160, -0.0907, -1.3947]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm.model[2](hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(2.3974, grad_fn=<DivBackward0>),\n",
       " 'logits': tensor([[[-1.5808,  1.1482, -1.7822,  ...,  2.1955,  1.0737,  0.1318],\n",
       "          [-0.2795, -0.2390,  0.3636,  ...,  0.2533,  0.9747, -0.7541],\n",
       "          [-1.4023, -1.1716, -1.8004,  ...,  0.6374,  0.5905, -0.6558],\n",
       "          ...,\n",
       "          [-0.5546,  0.6915, -0.9092,  ...,  1.2913, -0.2356, -0.1399],\n",
       "          [ 0.2118,  0.3902, -1.2860,  ...,  0.6158,  1.3520, -1.6078],\n",
       "          [ 0.5129,  0.2748, -0.9802,  ...,  0.8152,  0.9959, -1.2413]],\n",
       " \n",
       "         [[-1.7395,  0.0238, -1.9076,  ...,  2.2626,  1.2561,  0.0561],\n",
       "          [-0.0229, -0.0825, -0.0552,  ...,  0.2150,  1.0042, -1.3747],\n",
       "          [-0.8470, -0.9412, -1.2945,  ...,  0.7761,  1.0303, -0.8591],\n",
       "          ...,\n",
       "          [-0.2673,  0.4812, -1.2947,  ...,  1.0498, -0.8741, -0.3677],\n",
       "          [ 0.5930,  0.7765, -1.0648,  ...,  0.5665,  1.6461, -1.2059],\n",
       "          [ 0.3977,  0.3008, -0.7681,  ...,  0.5883,  0.5202, -1.3566]],\n",
       " \n",
       "         [[-1.3890, -0.1364, -1.7042,  ...,  1.6052,  1.4031,  0.3403],\n",
       "          [ 0.1938, -0.7083,  0.4247,  ...,  0.4151,  0.6913, -1.0923],\n",
       "          [-0.3815, -0.7984, -1.3648,  ...,  0.2202,  0.7836, -1.1829],\n",
       "          ...,\n",
       "          [-0.5707,  0.7899, -1.2249,  ...,  1.8686, -0.6524, -0.0498],\n",
       "          [ 0.0886,  0.6942, -1.2099,  ...,  0.5574,  1.7318, -1.2289],\n",
       "          [ 1.0629,  0.4200, -1.0675,  ...,  0.7388, -0.1062, -0.9928]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.3755,  1.0896, -2.3857,  ...,  2.0311,  1.0183,  0.1668],\n",
       "          [-0.0367, -0.4360, -0.5280,  ...,  0.3377,  1.3303, -0.9726],\n",
       "          [-0.2838, -0.5343, -1.2527,  ...,  0.1184,  0.7251, -1.2759],\n",
       "          ...,\n",
       "          [-0.4163,  0.6577, -1.4112,  ...,  1.2412, -0.5222, -0.3257],\n",
       "          [ 0.3312,  0.6211, -1.0823,  ...,  0.8027,  1.2026, -1.1733],\n",
       "          [ 0.2113, -0.0989, -1.2061,  ...,  0.7045, -0.0346, -1.3337]],\n",
       " \n",
       "         [[-1.6812,  1.0495, -2.2390,  ...,  1.6317,  1.1516,  0.3742],\n",
       "          [-0.1347, -0.0740,  0.5174,  ...,  0.1874,  0.9828, -0.8260],\n",
       "          [-0.9869, -0.6325, -1.7462,  ...,  0.4248,  0.7912, -1.2975],\n",
       "          ...,\n",
       "          [-0.4272,  0.7078, -1.4299,  ...,  1.0632, -0.3324, -0.5779],\n",
       "          [ 0.0953,  0.8127, -1.5130,  ...,  0.9852,  0.3943, -1.3130],\n",
       "          [ 0.8810, -0.0094, -0.9377,  ...,  0.6347,  0.0085, -1.3871]],\n",
       " \n",
       "         [[-1.8819, -0.1791, -0.9824,  ...,  2.3237,  1.6951,  0.1094],\n",
       "          [-0.3517, -0.3560,  0.6557,  ...,  0.2586,  1.0698, -1.3304],\n",
       "          [-0.5517, -0.6563, -1.5789,  ...,  0.0035,  1.2499, -1.0815],\n",
       "          ...,\n",
       "          [-0.8128,  0.4624, -0.7992,  ...,  1.3286, -0.4778, -0.0624],\n",
       "          [ 0.4903,  0.9188, -1.5413,  ...,  1.4586,  1.6053, -1.5239],\n",
       "          [ 0.8413, -0.0940, -0.8970,  ...,  0.7759,  0.2128, -1.4706]]],\n",
       "        grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n"
     ]
    }
   ],
   "source": [
    "from allennlp.training import Trainer\n",
    "\n",
    "optimizer = torch.optim.Adam(masked_lm.parameters(), lr=0.01)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=masked_lm,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    serialization_dir=None,\n",
    "    cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.4233 ||: 100%|██████████| 16/16 [13:54<00:00, 51.92s/it] \n",
      "loss: 0.9495 ||: 100%|██████████| 16/16 [01:19<00:00,  7.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 0,\n",
       " 'peak_cpu_memory_MB': 4138.745856,\n",
       " 'training_duration': '00:15:14',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 0,\n",
       " 'epoch': 0,\n",
       " 'training_loss': 1.423305545002222,\n",
       " 'training_cpu_memory_MB': 4138.745856,\n",
       " 'validation_loss': 0.9494792744517326,\n",
       " 'best_validation_loss': 0.9494792744517326}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17, 17, 17,  ..., 17, 17, 17],\n",
       "        [17, 17, 17,  ..., 17, 17, 17],\n",
       "        [17, 17, 17,  ..., 17, 17, 17],\n",
       "        ...,\n",
       "        [17, 17, 17,  ..., 17, 17, 17],\n",
       "        [17, 17, 17,  ..., 17, 17, 17],\n",
       "        [17, 17, 17,  ..., 17, 17, 17]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm(**batch)[\"logits\"].argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For IS loss, we need to aggregate the embeddings at the end of training to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "vocab_sz = vocab.get_vocab_size()\n",
    "embedding_sz = bert_config.hidden_size\n",
    "\n",
    "if config.loss == \"is\":\n",
    "    bs = 64\n",
    "    output_embedding_matrix = torch.zeros(vocab_sz, embedding_sz)\n",
    "    num_batches = math.ceil(vocab_sz / bs)\n",
    "    for i in range(num_batches):\n",
    "        start,end = i*bs, min(((i+1)*bs), vocab_sz)\n",
    "        idxs = torch.arange(start=start, end=end).unsqueeze(0)\n",
    "        output_embedding_matrix[start:end, :] = loss.get_embeddings(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Check Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement manual checks for negative sampling loss as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(t): return t.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(arr):\n",
    "    if len(arr.shape) > 1:\n",
    "        return [to_words(a) for a in arr]\n",
    "    else:\n",
    "        arr = to_np(arr)\n",
    "        return \" \".join([vocab.get_token_from_index(i) for i in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, batch: TensorDict):\n",
    "    if config.loss == \"is\":\n",
    "        logits = model(**batch)[\"logits\"]\n",
    "        return (logits @ output_embedding_matrix.transpose(0, 1)).argmax(2)\n",
    "    else:\n",
    "        return model(**batch)[\"logits\"].argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 128, 32])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm(**batch)[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cstm_pprint(x):\n",
    "    print(\"\\n\\n\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] \" Israeli \" \" Apartheid \" \" Article How dare you identify a very clear and reasonable allegation of bias as \" \" vandalism \" \" . I 'm disgusted with your behaviour , and your willingness to suppress arguments that do n't mesh with your ideological foundation . Considering that the page I edited deals with human rights , I find it very salient that you are more than willing to suppress the freedom of expression by turning this site into a dictatorship of the obsessive over the intelligent . -edit : I noticed that you removed my statement quite quickly . Is there some explanation for succumbing to such cowardice and refusing to address me directly ? —Preceding unsigned comment added by 138.40.153.43 \" [SEP]\n",
      "\n",
      "[CLS] It slows trains down because the existing speed limits already have a significant margin of safety built in so the engineer can exceed them by small amounts and still remain safe . With PTC such fluctuations over the posted limit will trigger an overspeed alarm with the result that crews will check their speed several mph below what is authorized . PTC does not increase capacity except possibly on low density lines that were previously not signaled . ACSES does not actually handle any sort of anti - colision duties . Those are covered by the legacy fixed block cab and wayside signaling system . On non - ACSES routes the PTC unit is attached to the wires leading to the wayside signal . If reliable [SEP]\n",
      "\n",
      "[CLS] \" Proposal to Delete this article . Notice how the only people who use this word are white or work for the white media ? ( I 'm white , btw , but this wikipedia and I 'm a volunteer ) . Someone that is Islamic , like one of the countless Muslim genius 's like Averroes or Avicenna or al - Khwarizmi , would not describe their work as \" \" Islamist \" \" . When Muhammad Ali did n't want to fight against Vietnam , his pacifism was n't Islamist . Sure , a true Muslim would not have supported or joined in the American war on Vietnam , but that is not called Islamism . Rather , Islamism is a word invented by [SEP]\n",
      "\n",
      "[CLS] ( reset indent ) Ignore policy ? You ca n't even point us to the relevant policy ! Nonetheless , how could Wiki possibly decide an article that has a criticism section could be a Featured Article ? Controversial subject ? PETA ? Really ? - list all the controversial items for me please . I did not ignore your response ; I thought my answer was clear but I 'll ride the donkey for ya . A single section containing criticisms is an example of a poorly structured article as it means that people reading about a subject have to look in the section about it for the ' non - criticism ' and then a second section to see if there is any criticism [SEP]\n",
      "\n",
      "[CLS] \" I meant to do that last night but some stupid shit came up . Then I went and helped move furniture at the church . I came home and did not feel like reading until my friends started trying to scare me by calling my phone and saying stupid things and just purely breathing on it . Then they tried to come to my house and scare me but I went to their 's and surprised the shit out of them . They came around the corner and went holy shit when they saw me and started running while I screamed run bitch at around 11 pm . I came home and just did small things on here . I 'll read it today , [SEP]\n"
     ]
    }
   ],
   "source": [
    "cstm_pprint(to_words(batch[\"output\"][\"words\"])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n"
     ]
    }
   ],
   "source": [
    "cstm_pprint(to_words(get_preds(masked_lm, batch))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "loss: 0.6985 ||: 100%|██████████| 16/16 [03:56<00:00, 10.56s/it]\n",
      "loss: 1.0746 ||: 100%|██████████| 16/16 [01:19<00:00,  8.11s/it]\n",
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.6535 ||: 100%|██████████| 16/16 [03:57<00:00, 13.05s/it]\n",
      "loss: 1.0837 ||: 100%|██████████| 16/16 [01:26<00:00,  8.46s/it]\n",
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.6538 ||: 100%|██████████| 16/16 [04:16<00:00, 18.29s/it]\n",
      "loss: 1.1413 ||: 100%|██████████| 16/16 [01:24<00:00,  7.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n",
      "\n",
      "this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this this\n"
     ]
    }
   ],
   "source": [
    "if config.debugging:\n",
    "    for i in range(3):\n",
    "        trainer = Trainer(\n",
    "            model=masked_lm,\n",
    "            optimizer=optimizer,\n",
    "            iterator=iterator,\n",
    "            train_dataset=train_ds,\n",
    "            validation_dataset=val_ds,\n",
    "            serialization_dir=None,\n",
    "            cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "            num_epochs=1,\n",
    "        )\n",
    "        trainer.train()\n",
    "        cstm_pprint(to_words(get_preds(masked_lm, batch))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
