{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for seamlessly running on colab\n",
    "import os\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.environ[\"IS_COLAB\"] = \"True\"\n",
    "except ImportError:\n",
    "    os.environ[\"IS_COLAB\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ \"$IS_COLAB\" = \"True\" ]; then\n",
    "    pip install git+https://github.com/facebookresearch/fastText.git\n",
    "    pip install torch\n",
    "    pip install torchvision\n",
    "    pip install allennlp\n",
    "    pip install dnspython\n",
    "    pip install jupyter_slack\n",
    "    pip install git+https://github.com/keitakurita/Better_LSTM_PyTorch.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from overrides import overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "import functools\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "def get_ref_free_exc_info():\n",
    "    \"Free traceback from references to locals/globals to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n",
    "    type, val, tb = sys.exc_info()\n",
    "    traceback.clear_frames(tb)\n",
    "    return (type, val, tb)\n",
    "\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = get_ref_free_exc_info() # must!\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper\n",
    "\n",
    "def ifnone(a: Any, alt: Any): return alt if a is None else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for papermill\n",
    "testing = True\n",
    "debugging = False\n",
    "seed = 1\n",
    "char_encoder = \"fasttext\"\n",
    "computational_batch_size = 64\n",
    "batch_size = 64\n",
    "lr = 4e-3\n",
    "lr_schedule = \"slanted_triangular\"\n",
    "epochs = 6 if not testing else 1\n",
    "hidden_sz = 128\n",
    "dataset = \"jigsaw\"\n",
    "n_classes = 6\n",
    "max_seq_len = 128\n",
    "download_data = False\n",
    "ft_model_path = \"../data/jigsaw/ft_model.txt\"\n",
    "max_vocab_size = 40000\n",
    "dropouti = 0.2\n",
    "dropoutw = 0.0\n",
    "dropoute = 0.2\n",
    "dropoutr = 0.3 # TODO: Implement\n",
    "val_ratio = 0.0\n",
    "use_augmented = False\n",
    "freeze_embeddings = True\n",
    "mixup_ratio = 0.0\n",
    "discrete_mixup_ratio = 0.0\n",
    "attention_bias = True\n",
    "weight_decay = 0.\n",
    "bias_init = True\n",
    "neg_splits = 1\n",
    "num_layers = 2\n",
    "rnn_type = \"lstm\"\n",
    "pooling_type = \"augmented_multipool\" # attention or multipool or augmented_multipool\n",
    "model_type = \"standard\"\n",
    "use_word_level_features = True\n",
    "use_sentence_level_features = True\n",
    "bucket = True\n",
    "compute_thres_on_test = True\n",
    "find_lr = False\n",
    "permute_sentences = False\n",
    "run_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can we make this play better with papermill?\n",
    "config = Config(\n",
    "    testing=testing,\n",
    "    debugging=debugging,\n",
    "    seed=seed,\n",
    "    char_encoder=char_encoder,\n",
    "    computational_batch_size=computational_batch_size,\n",
    "    batch_size=batch_size,\n",
    "    loss=\"crossentropy\",\n",
    "    lr=lr,\n",
    "    lr_schedule=lr_schedule,\n",
    "    epochs=epochs,\n",
    "    hidden_sz=hidden_sz,\n",
    "    dataset=dataset,\n",
    "    n_classes=n_classes,\n",
    "    max_seq_len=max_seq_len, # necessary to limit memory usage\n",
    "    ft_model_path=ft_model_path,\n",
    "    max_vocab_size=max_vocab_size,\n",
    "    dropouti=dropouti,\n",
    "    dropoutw=dropoutw,\n",
    "    dropoute=dropoute,\n",
    "    dropoutr=dropoutr,\n",
    "    val_ratio=val_ratio,\n",
    "    use_augmented=use_augmented,\n",
    "    freeze_embeddings=freeze_embeddings,\n",
    "    attention_bias=attention_bias,\n",
    "    weight_decay=weight_decay,\n",
    "    bias_init=bias_init,\n",
    "    neg_splits=neg_splits,\n",
    "    num_layers=num_layers,\n",
    "    rnn_type=rnn_type,\n",
    "    pooling_type=pooling_type,\n",
    "    model_type=model_type,\n",
    "    use_word_level_features=use_word_level_features,\n",
    "    use_sentence_level_features=use_sentence_level_features,\n",
    "    mixup_ratio=mixup_ratio,\n",
    "    discrete_mixup_ratio=discrete_mixup_ratio,\n",
    "    bucket=bucket,\n",
    "    compute_thres_on_test=compute_thres_on_test,\n",
    "    permute_sentences=permute_sentences,\n",
    "    find_lr=find_lr,\n",
    "    run_id=run_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "T = TypeVar(\"T\")\n",
    "TensorDict = Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]  # pylint: disable=invalid-name\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ[\"IS_COLAB\"] != \"True\":\n",
    "    DATA_ROOT = Path(\"../data\") / config.dataset\n",
    "else:\n",
    "    DATA_ROOT = Path(\"./gdrive/My Drive/Colab_Workspace/Colab Notebooks/data\") / config.dataset\n",
    "    config.ft_model_path = str(DATA_ROOT / \"ft_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "if download_data:\n",
    "    if config.val_ratio > 0.0:\n",
    "        fnames = [\"train_wo_val.csv\", \"test_proced.csv\", \"val.csv\", \"ft_model.txt\"]\n",
    "    else:\n",
    "        fnames = [\"train.csv\", \"test_proced.csv\", \"ft_model.txt\"]\n",
    "    if config.use_augmented or config.discrete_mixup_ratio > 0.0: fnames.append(\"train_extra.csv\")\n",
    "    for fname in fnames:\n",
    "        if not (DATA_ROOT / fname).exists():\n",
    "            print(subprocess.Popen([f\"aws s3 cp s3://nnfornlp/raw_data/jigsaw/{fname} {str(DATA_ROOT)}\"],\n",
    "                                   shell=True, stdout=subprocess.PIPE).stdout.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import (TextField, SequenceLabelField, LabelField, \n",
    "                                  MetadataField, ArrayField)\n",
    "\n",
    "class JigsawLMDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None, # TODO: Handle mapping from BERT\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def _clean(self, x: str) -> str:\n",
    "        \"\"\"\n",
    "        Maps a word to its desired output. Will leave as identity for now.\n",
    "        In the future, will change to denoising operation.\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[str]) -> Instance:\n",
    "        sentence_field = TextField([Token(x) for x in tokens],\n",
    "                                   self.token_indexers)\n",
    "        fields = {\"input\": sentence_field}\n",
    "        output_sentence_field = TextField([Token(self._clean(x)) for x in tokens],\n",
    "                                          self.token_indexers)\n",
    "        fields[\"output\"] = output_sentence_field\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                self.tokenizer(row[\"comment_text\"]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "\n",
    "if config.char_encoder == \"cnn\":\n",
    "    token_indexer = ELMoTokenCharactersIndexer()\n",
    "else:\n",
    "    token_indexer = SingleIdTokenIndexer(lowercase_tokens=True) # Temporary\n",
    "\n",
    "_spacy_tok = SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words\n",
    "\n",
    "def tokenizer(x: str):\n",
    "        return [\"[CLS]\"] + [w.text for w in\n",
    "                _spacy_tok(x)[:config.max_seq_len - 2]] + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:03, 313.20it/s]\n",
      "1000it [00:02, 441.27it/s]\n",
      "1000it [00:02, 370.82it/s]\n"
     ]
    }
   ],
   "source": [
    "reader = JigsawLMDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer},\n",
    ")\n",
    "train_ds, val_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train_wo_val.csv\",\n",
    "                                                                          \"val.csv\",\n",
    "                                                                          \"test_proced.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [[CLS],\n",
       "  How,\n",
       "  can,\n",
       "  my,\n",
       "  comment,\n",
       "  on,\n",
       "  my,\n",
       "  own,\n",
       "  talk,\n",
       "  page,\n",
       "  WP,\n",
       "  :,\n",
       "  DISRUPT,\n",
       "  wikipedia,\n",
       "  ?,\n",
       "  [SEP]],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer at 0x1a2c7fe358>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[2].fields[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 12427.40it/s]\n"
     ]
    }
   ],
   "source": [
    "full_ds = train_ds + test_ds + val_ds\n",
    "vocab = Vocabulary.from_instances(full_ds, tokens_to_add={\"tokens\": [\"[MASK]\"]},\n",
    "                                  max_vocab_size=config.max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build word to indices mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    # TODO: Speed up\n",
    "    # See allennlp/data/token_indexers/elmo_indexer.py\n",
    "    with timer(\"Building character indexes\"):\n",
    "        word_id_to_char_idxs = []\n",
    "        freqs = []\n",
    "        for w, freq in word_freqs.items():\n",
    "            # TODO: Check for start/end of word symbols\n",
    "            char_idxs = [258] + [int(c) for c in w.encode(\"utf-8\")] + [259]\n",
    "            word_id_to_char_idxs.append([x + 1 for x in char_idxs])\n",
    "            freqs.append(freqs)\n",
    "        word_id_to_char_idxs = np.array(word_id_to_char_idxs)\n",
    "        freqs = np.array(freqs)\n",
    "\n",
    "    word_id_to_char_idxs = torch.LongTensor(word_id_to_char_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement fast sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.zeros(vocab.get_vocab_size())\n",
    "for w, c in vocab._retained_counter[\"tokens\"].items():\n",
    "    freqs[vocab.get_token_index(w)] = c\n",
    "freqs /= freqs.sum()\n",
    "freqs **= 2 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator, DataIterator\n",
    "iterator = BucketIterator(\n",
    "        batch_size=config.batch_size, \n",
    "        biggest_batch_first=config.testing,\n",
    "        sorting_keys=[(\"input\", \"num_tokens\")],\n",
    ")\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterator(train_ds))[\"input\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'tokens': tensor([[   8,  243, 8678,  ...,  250, 8684,    9],\n",
       "          [   8,    5,   17,  ...,    0,    0,    0],\n",
       "          [   8,    5,   62,  ...,    3,  801,    9],\n",
       "          ...,\n",
       "          [   8,    5,   44,  ...,  153,    2,    9],\n",
       "          [   8,    5,   62,  ...,    2,   25,    9],\n",
       "          [   8,   38,  913,  ...,  135,   26,    9]])},\n",
       " 'output': {'tokens': tensor([[   8,  243, 8678,  ...,  250, 8684,    9],\n",
       "          [   8,    5,   17,  ...,    0,    0,    0],\n",
       "          [   8,    5,   62,  ...,    3,  801,    9],\n",
       "          ...,\n",
       "          [   8,    5,   44,  ...,  153,    2,    9],\n",
       "          [   8,    5,   62,  ...,    2,   25,    9],\n",
       "          [   8,   38,  913,  ...,  135,   26,    9]])}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building token embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    from allennlp.modules.token_embedders.elmo_token_embedder import ElmoTokenEmbedder\n",
    "    from allennlp.modules.elmo import _ElmoCharacterEncoder\n",
    "\n",
    "    options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "    weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "    char_encoder = _ElmoCharacterEncoder(\n",
    "        options_file=options_file, \n",
    "        weight_file=weight_file,\n",
    "        requires_grad=True\n",
    "    )\n",
    "\n",
    "# char_encoder\n",
    "\n",
    "# sample_idxs = next(iterator(train_ds))[\"tokens\"][\"tokens\"]\n",
    "\n",
    "# char_encoder(sample_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"boc\":\n",
    "    from torch.nn.modules.sparse import EmbeddingBag\n",
    "    # TODO: Customize\n",
    "    class FastTextEmbeddingBag(EmbeddingBag):\n",
    "        def __init__(self, model_path):\n",
    "            self.model = load_model(model_path)\n",
    "            input_matrix = self.model.get_input_matrix()\n",
    "            input_matrix_shape = input_matrix.shape\n",
    "            super().__init__(input_matrix_shape[0], input_matrix_shape[1])\n",
    "            self.weight.data.copy_(torch.FloatTensor(input_matrix))\n",
    "\n",
    "        def forward(self, words):\n",
    "            word_subinds = np.empty([0], dtype=np.int64)\n",
    "            word_offsets = [0]\n",
    "            for word in words:\n",
    "                _, subinds = self.model.get_subwords(word)\n",
    "                word_subinds = np.concatenate((word_subinds, subinds))\n",
    "                word_offsets.append(word_offsets[-1] + len(subinds))\n",
    "            word_offsets = word_offsets[:-1]\n",
    "            ind = Variable(torch.LongTensor(word_subinds))\n",
    "            offsets = Variable(torch.LongTensor(word_offsets))\n",
    "            return super().forward(ind, offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.modeling import (BertConfig, BertForMaskedLM, \n",
    "                                              BertEncoder, BertPooler, BertOnlyMLMHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = BertConfig(\n",
    "        config.max_vocab_size, hidden_size=32, num_attention_heads=4,\n",
    "        num_hidden_layers=4, intermediate_size=32 * 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 32,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 128,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 40000\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, temporarily use fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def get_fasttext_embeddings(model_path: str, vocab: Vocabulary):\n",
    "    prog_bar = tqdm(open(model_path, encoding=\"utf8\", errors='ignore'))\n",
    "    prog_bar.set_description(\"Loading embeddings\")\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in prog_bar\n",
    "                             if len(o)>100)\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "\n",
    "    embeddings = np.zeros((bert_config.vocab_size + 5, 300))\n",
    "    n_missing_tokens = 0\n",
    "    prog_bar = tqdm(vocab.get_index_to_token_vocabulary().items())\n",
    "    prog_bar.set_description(\"Creating matrix\")\n",
    "    for idx, token in prog_bar:\n",
    "        if idx == 0: continue # keep padding as all zeros\n",
    "        if idx == 1: continue # Treat unknown words as dropped words\n",
    "        if token == \"[MASK]\":\n",
    "            embeddings[idx, :] = np.random.randn(300) * 0.5\n",
    "        if token not in embeddings_index:\n",
    "            n_missing_tokens += 1\n",
    "            if n_missing_tokens < 10:\n",
    "                warnings.warn(f\"Token {token} not in embeddings: did you change preprocessing?\")\n",
    "            if n_missing_tokens == 10:\n",
    "                warnings.warn(f\"More than {n_missing_tokens} missing, supressing warnings\")\n",
    "        else:\n",
    "            embeddings[idx, :] = embeddings_index[token]\n",
    "    \n",
    "    if n_missing_tokens > 0:\n",
    "        warnings.warn(f\"{n_missing_tokens} in total are missing from embedding text file\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_matrix = np.random.randn(bert_config.vocab_size + 5, 300) * 0.3\n",
    "#get_fasttext_embeddings(str(DATA_ROOT / \"ft_model.txt\"), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(x):\n",
    "    x.requires_grad = False\n",
    "    if hasattr(x, \"parameters\"):\n",
    "        for p in x.parameters: freeze(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedding(Embedding):\n",
    "    def __init__(self, num_embeddings, embedding_dim, bert_hidden_sz,\n",
    "                 freeze_embeddings=False, dropout=0.1, **kwargs):\n",
    "        super().__init__(num_embeddings, embedding_dim, **kwargs)\n",
    "        if freeze_embeddings:\n",
    "            freeze(self.weight)\n",
    "        self.position_embeddings = nn.Embedding(config.max_seq_len, \n",
    "                                                bert_hidden_sz)\n",
    "        self.linear = nn.Linear(embedding_dim, bert_hidden_sz,\n",
    "                                bias=False) # Transform dimensions\n",
    "        self.norm = LayerNorm(bert_hidden_sz)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        # We won't be using token types since we won't be predicting the next sentence\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = (torch.arange(seq_length, dtype=torch.long)\n",
    "                             .to(input_ids.device)\n",
    "                             .unsqueeze(0)\n",
    "                             .expand_as(input_ids))\n",
    "        word_embs = self.linear(super().forward(input_ids))\n",
    "        position_embs = self.position_embeddings(position_ids)\n",
    "        return self.do(self.norm(word_embs + position_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embs = CustomEmbedding(bert_config.vocab_size + 5, \n",
    "                              300,\n",
    "                              bert_config.hidden_size,\n",
    "                              weight=torch.FloatTensor(ft_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomEmbedding(\n",
       "  (position_embeddings): Embedding(128, 32)\n",
       "  (linear): Linear(in_features=300, out_features=32, bias=False)\n",
       "  (norm): LayerNorm()\n",
       "  (do): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encoder = BertEncoder(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, embeddings, encoder):\n",
    "        super().__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def forward(self, input_ids, \n",
    "                token_type_ids=None, \n",
    "                attention_mask=None):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "        \n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
    "        encoded_layers = self.encoder(embedding_output,\n",
    "                                      extended_attention_mask,\n",
    "                                      output_all_encoded_layers=True)\n",
    "        return encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMLMPooler(nn.Module):\n",
    "    def forward(self, x: List[torch.FloatTensor]) -> torch.FloatTensor:\n",
    "        return x[-1] # return final layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = CustomBert(sample_embs, bert_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "class BertCustomLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config, embedding, output_logits=True):\n",
    "        super().__init__()\n",
    "        # Projections\n",
    "        self.dense = nn.Linear(config.hidden_size, embedding.shape[1])\n",
    "        self.transform_act_fn = gelu\n",
    "        self.LayerNorm = LayerNorm(embedding.shape[1])\n",
    "        \n",
    "        # Predictions\n",
    "        self.output_logits = output_logits\n",
    "        if self.output_logits:\n",
    "            self.decoder = nn.Linear(embedding.size(1), embedding.size(0), \n",
    "                                     bias=False)\n",
    "            self.decoder.weight = embedding\n",
    "            self.bias = nn.Parameter(torch.zeros(embedding.size(0)))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        if self.output_logits:\n",
    "            hidden_states = self.dense(hidden_states)\n",
    "            hidden_states = self.transform_act_fn(hidden_states)\n",
    "            preds = self.LayerNorm(hidden_states)\n",
    "            preds = self.decoder(preds) + self.bias\n",
    "        else:\n",
    "            preds = hidden_states\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mlm_head = BertCustomLMPredictionHead(bert_config, sample_embs.weight,\n",
    "                                           output_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = nn.Sequential(\n",
    "    bert_model,\n",
    "    BertMLMPooler(),\n",
    "    bert_mlm_head,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Sampling Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different decoder (TODO: Enable sharing of parameters)\n",
    "# char_decoder = _ElmoCharacterEncoder(\n",
    "#     options_file=options_file, \n",
    "#     weight_file=weight_file,\n",
    "#     requires_grad=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCorrection(nn.Module):\n",
    "    \"\"\"From the paper `Exploring the Limitations of Language Modeling`\"\"\"\n",
    "    def __init__(self, hidden_sz: int, bottleneck_sz: int=128):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(hidden_sz, bottleneck_sz)\n",
    "        \n",
    "    def forward(self, h: torch.FloatTensor, \n",
    "                corr: torch.FloatTensor):\n",
    "        x = self.l1(h)\n",
    "        return x @ corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unigram_noise(freq):\n",
    "    \"\"\"build the unigram noise from a list of frequency\n",
    "    Parameters:\n",
    "        freq: a tensor of #occurrences of the corresponding index\n",
    "    Return:\n",
    "        unigram_noise: a torch.Tensor with size ntokens,\n",
    "        elements indicate the probability distribution\n",
    "    \"\"\"\n",
    "    total = freq.sum()\n",
    "    noise = freq / total\n",
    "    assert abs(noise.sum() - 1) < 0.001\n",
    "    return noise ** 0.75 # slight modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportanceSamplingLoss(nn.Module):\n",
    "    def __init__(self, embedding_generator: nn.Module,\n",
    "                 probs: np.ndarray, k=10):\n",
    "        super().__init__()\n",
    "        self.embedding_generator = embedding_generator\n",
    "        # TODO: Should this be according to the unigram probability?\n",
    "        # Or should it be uniform?\n",
    "        self.sampler = Categorical(probs=probs)\n",
    "        # TODO: Compute samples in advance\n",
    "        self._loss_func = nn.CrossEntropyLoss()\n",
    "        self.k = k\n",
    "    \n",
    "    def get_negative_samples(self, bs) -> torch.LongTensor:\n",
    "        neg = self.sampler.sample((bs, self.k, )) # TODO: Speed up??\n",
    "        return neg\n",
    "    \n",
    "    def get_embeddings(self, idxs: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Converts indexes into vectors\"\"\"\n",
    "        return self.embedding_generator(idxs, None) # TODO: Implement general case\n",
    "    \n",
    "    def forward(self, y: torch.LongTensor, tgt):\n",
    "        \"\"\"\n",
    "        Expects input of shape\n",
    "        y: (batch * seq, feature_sz)\n",
    "        tgt: (batch * seq, )\n",
    "        \"\"\"\n",
    "        bs = y.size(0)\n",
    "        neg_samples = self.get_negative_samples(bs)\n",
    "        idxs = torch.cat([tgt.unsqueeze(1), neg_samples], dim=1)\n",
    "        # TODO: More efficient implementation? (Ask TAs)\n",
    "        dot_prods = torch.bmm(y.unsqueeze(1), \n",
    "                              self.get_embeddings(idxs).transpose(1, 2)).squeeze(1)\n",
    "        return self._loss_func(dot_prods, torch.zeros(bs, dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn((3, 7, bert_config.hidden_size)).view((-1, bert_config.hidden_size))\n",
    "tgt = torch.randint(100, (3, 7)).view((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorical(probs=torch.rand(100, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = cat.sample((y.size(0), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.cat([tgt.unsqueeze(1), neg_samples], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11, 32])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embs(idxs, None).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 32])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(y.unsqueeze(1), sample_embs(idxs, None).transpose(1, 2)).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.5355, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = ImportanceSamplingLoss(\n",
    "    sample_embs, probs=torch.rand(100),\n",
    ")\n",
    "loss(y, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masker(nn.Module):\n",
    "    def __init__(self, vocab: Vocabulary, \n",
    "                 noise_rate: float=0.15,\n",
    "                 mask_rate=0.8,\n",
    "                 replace_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.vocab_sz = vocab.get_vocab_size()\n",
    "        self.mask_id = vocab.get_token_index(\"[MASK]\")\n",
    "        self.noise_rate = noise_rate\n",
    "        self.mask_rate = mask_rate\n",
    "        self.replace_rate = replace_rate\n",
    "        \n",
    "    def create_mask(self, x, ones_ratio, dtype=torch.uint8):\n",
    "        return (torch.ones(x.shape, dtype=dtype, \n",
    "                           requires_grad=False)\n",
    "                     .bernoulli(ones_ratio))\n",
    "\n",
    "    def forward(self, x: torch.LongTensor) -> torch.LongTensor:\n",
    "        if self.train and self.noise_rate > 0:\n",
    "            mask = self.create_mask(x, self.noise_rate * self.mask_rate)\n",
    "            x = x.masked_fill(mask, self.mask_id)\n",
    "            if self.replace_rate > 0.:\n",
    "                # this is techinically incorrect, since we might overwrite the mask tokens\n",
    "                # but I guess it will do for now\n",
    "                mask = self.create_mask(x, 1 - self.noise_rate * self.replace_rate,\n",
    "                                        dtype=x.dtype)\n",
    "                # TODO: Should we really sample uniformly?\n",
    "                x = x * mask + torch.randint(self.vocab_sz, x.shape) * (1 - mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, preds, tgts, mask=None) -> torch.tensor:\n",
    "        if mask is None:\n",
    "            return self._loss(preds, tgts).mean()\n",
    "        else:\n",
    "            # Is this reshaping really necessary? Seems like there would be a more elegant solution\n",
    "            loss = self._loss(preds.view((-1, preds.size(-1))),\n",
    "                              tgts.view((-1, )))\n",
    "            n_elements = mask.sum()\n",
    "            return (loss * mask.view((-1, )).float()).sum() / n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "\n",
    "class MaskedLM(Model):\n",
    "    def __init__(self, vocab: Vocabulary, model: nn.Module,\n",
    "                loss: nn.Module, noise_rate=0.8):\n",
    "        super().__init__(vocab)\n",
    "        self.masker = Masker(vocab, noise_rate=noise_rate)\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "    \n",
    "    @property\n",
    "    def outputs_logits(self) -> bool:\n",
    "        return self.model[-1].output_logits\n",
    "    \n",
    "    def forward(self, input: TensorDict, \n",
    "                output: TensorDict, **kwargs) -> TensorDict:\n",
    "        mask = get_text_field_mask(input)\n",
    "        x = self.masker(input[\"tokens\"])\n",
    "        logits = self.model(x)\n",
    "        out_dict = {\"loss\": self.loss(logits, output[\"tokens\"], mask=mask)}\n",
    "        out_dict[\"logits\"] = logits\n",
    "        if self.outputs_logits:\n",
    "            out_dict[\"accuracy\"] = self.accuracy(logits, output[\"tokens\"])\n",
    "        return out_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        if self.outputs_logits:\n",
    "            return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
    "        else:\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.loss == \"masked_crossentropy\":\n",
    "    loss = MaskedCrossEntropyLoss()\n",
    "elif config.loss == \"crossentropy\":\n",
    "    _loss = nn.CrossEntropyLoss()\n",
    "    def ce(y, t, mask=None): \n",
    "        return _loss(y.view((-1, y.size(-1))), t.view((-1, )))\n",
    "    loss = ce\n",
    "elif config.loss == \"is\":\n",
    "    # TODO: Implement masking\n",
    "    loss = ImportanceSamplingLoss(sample_embs, torch.FloatTensor(freqs))\n",
    "else:\n",
    "    raise ValueError(\"AAAAAAAAAAAAA\")\n",
    "masked_lm = MaskedLM(vocab, custom_model, loss, noise_rate=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = masked_lm.masker(batch[\"input\"][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = masked_lm.model[:2](tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.9257e-01,  3.3017e-01, -1.9341e+00,  ...,  2.2470e+00,\n",
       "           8.4122e-04, -1.4128e+00],\n",
       "         [ 7.8955e-01, -5.5334e-01, -8.7381e-01,  ...,  1.2595e+00,\n",
       "          -1.3412e-01, -1.7660e+00],\n",
       "         [ 2.9464e+00,  9.1522e-02,  6.1226e-01,  ...,  1.1923e+00,\n",
       "           1.6033e+00, -5.0738e-01],\n",
       "         ...,\n",
       "         [ 3.5568e-01, -2.5305e+00,  7.2234e-01,  ...,  1.5066e+00,\n",
       "          -3.3546e-01, -1.9514e-01],\n",
       "         [ 1.9070e+00, -1.4500e+00,  6.1093e-01,  ..., -1.5661e-01,\n",
       "           1.2132e+00, -3.2763e-01],\n",
       "         [-1.5238e+00, -5.9411e-01,  5.3762e-01,  ...,  1.0543e-01,\n",
       "          -1.8073e+00,  5.3456e-01]],\n",
       "\n",
       "        [[ 7.9084e-01,  2.6551e-01, -2.2540e+00,  ...,  2.0175e+00,\n",
       "          -1.1645e-01, -1.2852e+00],\n",
       "         [ 5.6060e-01, -4.4838e-01, -2.5647e-01,  ...,  1.2451e+00,\n",
       "          -4.1708e-01, -1.5916e+00],\n",
       "         [ 2.6489e+00,  3.6799e-01,  3.7464e-01,  ...,  1.1297e+00,\n",
       "           2.3959e+00, -6.0559e-01],\n",
       "         ...,\n",
       "         [-3.3035e-01, -2.0894e+00, -1.2293e-02,  ...,  1.5888e+00,\n",
       "          -5.4225e-01, -3.0037e-01],\n",
       "         [ 1.5690e+00, -1.1017e+00,  9.7083e-02,  ..., -2.9587e-01,\n",
       "           1.2825e+00, -7.7247e-01],\n",
       "         [-9.1786e-02, -7.8914e-01,  3.8683e-01,  ...,  6.6879e-01,\n",
       "          -1.3828e+00, -1.4825e-01]],\n",
       "\n",
       "        [[ 9.0490e-01,  5.0617e-01, -2.3151e+00,  ...,  2.3610e+00,\n",
       "           2.1389e-01, -9.6520e-01],\n",
       "         [ 9.9986e-01, -4.7154e-01, -3.0964e-01,  ...,  1.2952e+00,\n",
       "          -3.4026e-01, -1.5869e+00],\n",
       "         [ 2.6587e+00,  4.9595e-01,  4.5266e-01,  ...,  1.2612e+00,\n",
       "           2.2924e+00, -5.0162e-01],\n",
       "         ...,\n",
       "         [ 5.5859e-02, -2.1029e+00, -3.4791e-01,  ...,  1.6520e+00,\n",
       "          -3.3659e-01,  4.6613e-01],\n",
       "         [ 2.3329e+00, -8.3004e-01,  2.0177e-01,  ...,  5.6635e-01,\n",
       "           7.9066e-01, -2.3736e-01],\n",
       "         [-4.8910e-01, -1.1657e+00,  9.5280e-01,  ...,  1.7354e-01,\n",
       "          -4.7092e-01,  3.1916e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.7089e-01,  3.9929e-01, -2.3886e+00,  ...,  2.2622e+00,\n",
       "           3.0476e-01, -1.2406e+00],\n",
       "         [ 9.1557e-01, -7.2691e-01, -5.8197e-01,  ...,  1.5904e+00,\n",
       "          -7.6473e-01, -2.0490e+00],\n",
       "         [ 2.2469e+00,  4.9786e-01,  5.8351e-01,  ...,  1.1440e+00,\n",
       "           1.6815e+00,  6.9722e-02],\n",
       "         ...,\n",
       "         [ 9.6021e-01, -2.8020e+00, -5.4709e-01,  ...,  2.1476e+00,\n",
       "          -1.8041e+00, -2.8434e-01],\n",
       "         [ 1.1924e+00, -1.0049e+00,  6.8357e-01,  ..., -1.3643e+00,\n",
       "           1.2548e+00, -6.7630e-01],\n",
       "         [ 2.9575e-02, -1.0162e+00,  6.5556e-01,  ...,  7.1583e-01,\n",
       "          -1.1894e+00, -7.5540e-02]],\n",
       "\n",
       "        [[ 1.1110e+00,  8.4171e-01, -2.0510e+00,  ...,  2.2929e+00,\n",
       "           2.0656e-01, -1.2904e+00],\n",
       "         [ 6.2157e-01, -2.0052e-01, -6.8760e-01,  ...,  1.2940e+00,\n",
       "          -2.4295e-01, -1.8025e+00],\n",
       "         [ 2.3955e+00,  5.9177e-01,  5.4201e-01,  ...,  1.5238e+00,\n",
       "           1.9583e+00,  8.9767e-02],\n",
       "         ...,\n",
       "         [-1.0726e-01, -2.6438e+00,  9.8838e-02,  ...,  1.8420e+00,\n",
       "          -9.2099e-01, -4.8420e-02],\n",
       "         [ 1.2383e+00, -1.1291e+00,  5.2903e-01,  ...,  6.1574e-02,\n",
       "           1.1361e+00, -7.9497e-01],\n",
       "         [-3.5623e-01, -7.5674e-01,  4.2197e-01,  ...,  4.9955e-01,\n",
       "          -8.8147e-01, -1.6440e-01]],\n",
       "\n",
       "        [[-3.0774e-01,  5.5426e-01, -1.3846e+00,  ...,  2.3533e+00,\n",
       "           3.0392e-02, -1.1238e+00],\n",
       "         [ 7.2105e-01, -1.5824e-01, -6.0472e-01,  ...,  1.4416e+00,\n",
       "          -7.6806e-01, -1.7795e+00],\n",
       "         [ 2.4360e+00,  1.2516e-01,  4.2964e-01,  ...,  1.0400e+00,\n",
       "           2.5251e+00, -5.5784e-01],\n",
       "         ...,\n",
       "         [-5.5858e-01, -1.8403e+00, -9.5413e-02,  ...,  1.2496e+00,\n",
       "          -2.8604e-01,  9.3116e-02],\n",
       "         [ 2.2699e+00, -4.3364e-01,  7.0991e-01,  ..., -2.2755e-01,\n",
       "           1.2805e-01,  3.2395e-03],\n",
       "         [-4.3073e-01, -1.0048e+00,  4.8225e-01,  ...,  4.1328e-01,\n",
       "          -1.1498e+00,  1.2605e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  2.3681,   2.3155,  -1.8459,  ...,   4.3093,  -0.5433,   4.8540],\n",
       "         [ -1.8181,  -0.3749,  -0.1832,  ...,   5.3945,   2.9493,  -3.0373],\n",
       "         [ -5.8419,   0.0406,   6.6328,  ...,  -5.5296,  -0.8188,   7.1563],\n",
       "         ...,\n",
       "         [  1.1825,   3.1556,   6.2975,  ...,   3.0837, -10.9357,   7.4305],\n",
       "         [  5.6680,   4.5227,   3.6175,  ...,  -1.2479,  -7.5419,   6.1736],\n",
       "         [ -5.2398,   4.8604,   5.4095,  ...,   9.5512,   8.7998,  -1.7505]],\n",
       "\n",
       "        [[ -0.6243,   4.0400,  -2.1453,  ...,   2.2620,   0.6276,   4.3817],\n",
       "         [  3.9622,  -2.1417,  -1.3703,  ...,  10.5944,   1.8270,  -5.2715],\n",
       "         [ -2.1944,  -0.5615,   4.8347,  ...,  -5.5999,  -1.3051,   6.3563],\n",
       "         ...,\n",
       "         [  4.8018,   1.1742,   2.9209,  ...,   5.4262,  -2.5404,   5.8397],\n",
       "         [  6.8405,   4.9000,   3.9885,  ...,  -1.9911,  -8.4598,   3.8191],\n",
       "         [ -6.5504,   7.3194,   1.9782,  ...,   2.4225,   7.8605,  -0.0655]],\n",
       "\n",
       "        [[ -0.3907,   3.9685,  -2.0745,  ...,   2.8664,   2.5401,   2.5544],\n",
       "         [ -1.4235,   0.0155,   1.4743,  ...,   4.0770,   3.6294,  -1.7778],\n",
       "         [ -5.9921,  -0.0670,   7.1543,  ...,  -5.5260,  -0.8163,   6.1710],\n",
       "         ...,\n",
       "         [  1.4975,   2.4201,   5.0598,  ...,   3.3072,  -8.3669,   2.7727],\n",
       "         [  3.6073,  -0.4557,   4.2045,  ...,  -4.0859,  -3.1270,   3.4656],\n",
       "         [ -2.9683,   3.9208,   4.2491,  ...,   3.6088,   8.3857,   4.0912]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.3927,   2.7901,  -2.0594,  ...,   4.7006,   0.3043,   2.1516],\n",
       "         [ -1.5229,  -3.1684,   2.7735,  ...,   5.4870,   2.6826,  -3.4860],\n",
       "         [ -5.1449,   0.5153,   6.5605,  ...,  -6.4462,  -0.0589,   9.2215],\n",
       "         ...,\n",
       "         [  3.5350,   1.1330,   6.4150,  ...,  11.9006,  -7.4887,  -2.2049],\n",
       "         [  6.2951,   2.7503,   6.3243,  ...,  -3.7192,  -0.8899,   6.6805],\n",
       "         [ -6.0057,   7.2466,   3.1879,  ...,   2.4013,   6.9240,   1.4175]],\n",
       "\n",
       "        [[ -1.4047,   5.2957,  -1.5363,  ...,   3.8745,   0.8031,   4.2725],\n",
       "         [ -1.4445,   0.5011,  -1.2557,  ...,   6.5793,   2.8309,  -1.9546],\n",
       "         [ -3.9269,  -0.5249,   5.3838,  ...,  -7.5375,   0.3220,   6.7766],\n",
       "         ...,\n",
       "         [  3.4297,   1.0667,   4.0096,  ...,  11.4519,  -7.4067,   3.5008],\n",
       "         [  7.3335,   4.5858,   3.0636,  ...,   4.1167, -10.4588,   2.2453],\n",
       "         [ -3.0654,   6.4429,   2.5024,  ...,   3.6388,   8.2667,   2.5956]],\n",
       "\n",
       "        [[  2.4319,   1.0976,  -2.0775,  ...,   8.6505,  -1.2403,   4.6283],\n",
       "         [ -2.7205,  -1.7077,  -0.1355,  ...,   3.0262,   5.3658,  -6.0587],\n",
       "         [ -3.9935,   0.6556,   8.1010,  ...,  -0.8746,  -1.8932,   7.2379],\n",
       "         ...,\n",
       "         [  4.4654,   2.6527,   3.7648,  ...,   2.2015,  -5.6983,   7.4016],\n",
       "         [ -0.8364,  -2.1582,   6.2567,  ...,  -8.0201,  -3.1604,   6.5089],\n",
       "         [ -3.8499,   6.0964,   1.9342,  ...,   3.6263,   8.2050,   3.0082]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm.model[2](hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n"
     ]
    }
   ],
   "source": [
    "from allennlp.training import Trainer\n",
    "\n",
    "optimizer = torch.optim.Adam(masked_lm.parameters(), lr=0.01)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=masked_lm,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    serialization_dir=None,\n",
    "    cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0473, loss: 12.3293 ||: 100%|██████████| 16/16 [01:22<00:00,  3.84s/it]\n",
      "accuracy: 0.1600, loss: 7.7848 ||: 100%|██████████| 16/16 [00:33<00:00,  3.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 0,\n",
       " 'peak_cpu_memory_MB': 2642.382848,\n",
       " 'training_duration': '00:01:56',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 0,\n",
       " 'epoch': 0,\n",
       " 'training_accuracy': 0.047279228855721396,\n",
       " 'training_loss': 12.32925209403038,\n",
       " 'training_cpu_memory_MB': 2642.382848,\n",
       " 'validation_accuracy': 0.1599829889112903,\n",
       " 'validation_loss': 7.784813791513443,\n",
       " 'best_validation_accuracy': 0.1599829889112903,\n",
       " 'best_validation_loss': 7.784813791513443}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2464e+01,  4.8041e-01,  9.9983e+00,  ..., -2.2404e-01,\n",
       "          -1.3467e+00, -1.4002e+00],\n",
       "         [ 1.0214e+01, -4.7934e-01,  1.1212e+01,  ...,  1.1572e+00,\n",
       "          -1.2680e+00, -2.0720e+00],\n",
       "         [ 1.1160e+01, -6.3993e-01,  1.0217e+01,  ...,  1.4380e-01,\n",
       "          -7.9035e-01, -1.1506e+00],\n",
       "         ...,\n",
       "         [ 1.1929e+01,  5.9776e-01,  1.0373e+01,  ...,  9.4615e-01,\n",
       "          -1.8114e+00, -2.3422e+00],\n",
       "         [ 1.2395e+01,  2.2977e-01,  9.2476e+00,  ..., -7.4081e-01,\n",
       "          -8.9187e-01, -9.6294e-01],\n",
       "         [ 1.4495e+01,  1.3644e+00,  8.9255e+00,  ..., -8.7293e-01,\n",
       "          -1.1923e+00, -8.4349e-01]],\n",
       "\n",
       "        [[ 1.2144e+01,  5.2355e-01,  1.0376e+01,  ..., -4.4624e-01,\n",
       "          -1.2708e+00, -1.6591e+00],\n",
       "         [ 9.9819e+00, -3.7882e-01,  1.1470e+01,  ...,  1.2626e+00,\n",
       "          -1.3926e+00, -2.4874e+00],\n",
       "         [ 1.3420e+01,  4.3167e-01,  7.9241e+00,  ...,  7.5914e-01,\n",
       "          -1.2522e+00, -1.0451e+00],\n",
       "         ...,\n",
       "         [ 1.4919e+01,  1.5384e+00,  8.4462e+00,  ..., -3.4928e-01,\n",
       "          -1.6461e+00, -7.5858e-01],\n",
       "         [ 1.4770e+01,  1.4591e+00,  8.3187e+00,  ..., -6.1310e-01,\n",
       "          -1.3948e+00, -6.5901e-01],\n",
       "         [ 1.4905e+01,  1.5063e+00,  8.6098e+00,  ..., -5.5961e-01,\n",
       "          -1.5355e+00, -7.2233e-01]],\n",
       "\n",
       "        [[ 1.2120e+01,  4.9290e-01,  1.0359e+01,  ..., -4.3717e-01,\n",
       "          -1.3051e+00, -1.6326e+00],\n",
       "         [ 1.1022e+01, -2.7544e-01,  1.0386e+01,  ...,  1.0168e+00,\n",
       "          -1.1095e+00, -1.6910e+00],\n",
       "         [ 1.0164e+01, -7.5850e-01,  1.1037e+01,  ...,  3.9613e-01,\n",
       "          -9.4104e-01, -1.6077e+00],\n",
       "         ...,\n",
       "         [ 1.1058e+01, -4.2979e-01,  9.5972e+00,  ...,  1.1852e-01,\n",
       "          -7.0123e-01, -1.0013e+00],\n",
       "         [ 1.2193e+01, -3.3839e-03,  9.4464e+00,  ..., -5.5144e-01,\n",
       "          -8.5911e-01, -1.1417e+00],\n",
       "         [ 1.4442e+01,  1.3580e+00,  8.8832e+00,  ..., -9.0641e-01,\n",
       "          -1.1946e+00, -8.1860e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2079e+01,  4.7760e-01,  1.0416e+01,  ..., -4.4337e-01,\n",
       "          -1.2768e+00, -1.6396e+00],\n",
       "         [ 9.9014e+00, -4.3311e-01,  1.1513e+01,  ...,  1.3716e+00,\n",
       "          -1.4384e+00, -2.5078e+00],\n",
       "         [ 1.1740e+01, -3.4858e-01,  9.6742e+00,  ...,  7.0461e-03,\n",
       "          -5.5504e-01, -1.0160e+00],\n",
       "         ...,\n",
       "         [ 1.3655e+01,  1.2879e+00,  9.5505e+00,  ..., -6.0845e-01,\n",
       "          -1.4205e+00, -1.6547e+00],\n",
       "         [ 1.0024e+01, -5.2351e-01,  1.1387e+01,  ...,  6.0673e-01,\n",
       "          -1.1867e+00, -1.9734e+00],\n",
       "         [ 1.4528e+01,  1.3593e+00,  8.8787e+00,  ..., -9.2104e-01,\n",
       "          -1.1754e+00, -7.9054e-01]],\n",
       "\n",
       "        [[ 1.2391e+01,  4.3709e-01,  1.0011e+01,  ..., -2.8431e-01,\n",
       "          -1.2996e+00, -1.3598e+00],\n",
       "         [ 9.9589e+00, -4.0389e-01,  1.1479e+01,  ...,  1.3368e+00,\n",
       "          -1.4341e+00, -2.4824e+00],\n",
       "         [ 1.0059e+01, -8.0186e-01,  1.1103e+01,  ...,  3.6761e-01,\n",
       "          -9.0850e-01, -1.6321e+00],\n",
       "         ...,\n",
       "         [ 9.8926e+00, -4.0191e-01,  1.1562e+01,  ...,  8.5462e-01,\n",
       "          -1.2301e+00, -2.1919e+00],\n",
       "         [ 1.2266e+01,  2.2676e-01,  9.4496e+00,  ..., -3.7929e-01,\n",
       "          -6.9513e-01, -1.0401e+00],\n",
       "         [ 1.4455e+01,  1.3622e+00,  8.8725e+00,  ..., -8.8186e-01,\n",
       "          -1.2016e+00, -8.1033e-01]],\n",
       "\n",
       "        [[ 1.2022e+01,  4.5489e-01,  1.0445e+01,  ..., -4.4629e-01,\n",
       "          -1.2752e+00, -1.6585e+00],\n",
       "         [ 9.8542e+00, -6.3961e-01,  1.1143e+01,  ...,  5.9213e-01,\n",
       "          -8.7638e-01, -1.7552e+00],\n",
       "         [ 1.0102e+01, -9.7136e-01,  1.1538e+01,  ...,  8.1293e-01,\n",
       "          -1.1473e+00, -2.0183e+00],\n",
       "         ...,\n",
       "         [ 1.1577e+01,  1.5557e-01,  9.5442e+00,  ...,  1.9146e-01,\n",
       "          -7.3715e-01, -1.1677e+00],\n",
       "         [ 1.2178e+01,  1.7666e-01,  9.4993e+00,  ..., -3.3425e-01,\n",
       "          -6.6482e-01, -1.0462e+00],\n",
       "         [ 1.4513e+01,  1.3663e+00,  8.8624e+00,  ..., -9.4302e-01,\n",
       "          -1.1596e+00, -7.8998e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm(**batch)[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = masked_lm.model[:2](tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  5,  4,  ...,  5, 43,  9],\n",
       "        [ 7,  5,  0,  ...,  0,  0,  0],\n",
       "        [ 7,  5,  5,  ..., 43,  7,  9],\n",
       "        ...,\n",
       "        [ 7,  5, 35,  ...,  9,  5,  9],\n",
       "        [ 7,  5,  5,  ...,  7,  7,  9],\n",
       "        [ 7,  5,  5,  ...,  5,  4,  9]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm(**batch)[\"logits\"].argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=masked_lm,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    serialization_dir=None,\n",
    "    cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0852, loss: 7.4609 ||:  31%|███▏      | 5/16 [00:37<01:19,  7.25s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm(**batch)[\"logits\"].argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=masked_lm,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    serialization_dir=None,\n",
    "    cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "    num_epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Check Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement manual checks for negative sampling loss as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(arr):\n",
    "    arr = to_np(arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
