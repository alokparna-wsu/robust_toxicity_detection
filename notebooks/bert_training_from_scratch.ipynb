{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from overrides import overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "import functools\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "def get_ref_free_exc_info():\n",
    "    \"Free traceback from references to locals/globals to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n",
    "    type, val, tb = sys.exc_info()\n",
    "    traceback.clear_frames(tb)\n",
    "    return (type, val, tb)\n",
    "\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = get_ref_free_exc_info() # must!\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper\n",
    "\n",
    "def ifnone(a: Any, alt: Any): return alt if a is None else a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for papermill\n",
    "testing = True\n",
    "debugging = False\n",
    "seed = 1\n",
    "char_encoder = \"fasttext\"\n",
    "computational_batch_size = 16\n",
    "batch_size = 16\n",
    "lr = 4e-3\n",
    "lr_schedule = \"slanted_triangular\"\n",
    "epochs = 6 if not testing else 1\n",
    "hidden_sz = 128\n",
    "dataset = \"jigsaw\"\n",
    "n_classes = 6\n",
    "max_seq_len = 512\n",
    "download_data = False\n",
    "ft_model_path = \"../data/jigsaw/ft_model.txt\"\n",
    "max_vocab_size = 40000\n",
    "dropouti = 0.2\n",
    "dropoutw = 0.0\n",
    "dropoute = 0.2\n",
    "dropoutr = 0.3 # TODO: Implement\n",
    "val_ratio = 0.0\n",
    "use_augmented = False\n",
    "freeze_embeddings = True\n",
    "mixup_ratio = 0.0\n",
    "discrete_mixup_ratio = 0.0\n",
    "attention_bias = True\n",
    "weight_decay = 0.\n",
    "bias_init = True\n",
    "neg_splits = 1\n",
    "num_layers = 2\n",
    "rnn_type = \"lstm\"\n",
    "pooling_type = \"augmented_multipool\" # attention or multipool or augmented_multipool\n",
    "model_type = \"standard\"\n",
    "use_word_level_features = True\n",
    "use_sentence_level_features = True\n",
    "bucket = True\n",
    "compute_thres_on_test = True\n",
    "find_lr = False\n",
    "permute_sentences = False\n",
    "run_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can we make this play better with papermill?\n",
    "config = Config(\n",
    "    testing=testing,\n",
    "    debugging=debugging,\n",
    "    seed=seed,\n",
    "    char_encoder=char_encoder,\n",
    "    computational_batch_size=computational_batch_size,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    lr_schedule=lr_schedule,\n",
    "    epochs=epochs,\n",
    "    hidden_sz=hidden_sz,\n",
    "    dataset=dataset,\n",
    "    n_classes=n_classes,\n",
    "    max_seq_len=max_seq_len, # necessary to limit memory usage\n",
    "    ft_model_path=ft_model_path,\n",
    "    max_vocab_size=max_vocab_size,\n",
    "    dropouti=dropouti,\n",
    "    dropoutw=dropoutw,\n",
    "    dropoute=dropoute,\n",
    "    dropoutr=dropoutr,\n",
    "    val_ratio=val_ratio,\n",
    "    use_augmented=use_augmented,\n",
    "    freeze_embeddings=freeze_embeddings,\n",
    "    attention_bias=attention_bias,\n",
    "    weight_decay=weight_decay,\n",
    "    bias_init=bias_init,\n",
    "    neg_splits=neg_splits,\n",
    "    num_layers=num_layers,\n",
    "    rnn_type=rnn_type,\n",
    "    pooling_type=pooling_type,\n",
    "    model_type=model_type,\n",
    "    use_word_level_features=use_word_level_features,\n",
    "    use_sentence_level_features=use_sentence_level_features,\n",
    "    mixup_ratio=mixup_ratio,\n",
    "    discrete_mixup_ratio=discrete_mixup_ratio,\n",
    "    bucket=bucket,\n",
    "    compute_thres_on_test=compute_thres_on_test,\n",
    "    permute_sentences=permute_sentences,\n",
    "    find_lr=find_lr,\n",
    "    run_id=run_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar(\"T\")\n",
    "TensorDict = Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]  # pylint: disable=invalid-name\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data/jigsaw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import (TextField, SequenceLabelField, LabelField, \n",
    "                                  MetadataField, ArrayField)\n",
    "\n",
    "class JigsawLMDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None, # TODO: Handle mapping from BERT\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def _clean(self, x: str) -> str:\n",
    "        \"\"\"\n",
    "        Maps a word to its desired output. Will leave as identity for now.\n",
    "        In the future, will change to denoising operation.\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[str]) -> Instance:\n",
    "        sentence_field = TextField([Token(x) for x in tokens],\n",
    "                                   self.token_indexers)\n",
    "        fields = {\"input\": sentence_field}\n",
    "        output_sentence_field = TextField([Token(self._clean(x)) for x in tokens],\n",
    "                                          self.token_indexers)\n",
    "        fields[\"output\"] = output_sentence_field\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                self.tokenizer(row[\"comment_text\"]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "\n",
    "if config.char_encoder == \"cnn\":\n",
    "    token_indexer = ELMoTokenCharactersIndexer()\n",
    "else:\n",
    "    token_indexer = SingleIdTokenIndexer(lowercase_tokens=True) # Temporary\n",
    "\n",
    "_spacy_tok = SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words\n",
    "\n",
    "def tokenizer(x: str):\n",
    "        return [w.text for w in\n",
    "                _spacy_tok(x)[:config.max_seq_len]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:04, 240.69it/s]\n",
      "1000it [00:03, 325.28it/s]\n",
      "1000it [00:03, 294.16it/s]\n"
     ]
    }
   ],
   "source": [
    "reader = JigsawLMDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer},\n",
    ")\n",
    "train_ds, val_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train_wo_val.csv\",\n",
    "                                                                          \"val.csv\",\n",
    "                                                                          \"test_proced.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2019 15:59:19 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 8527.69it/s]\n"
     ]
    }
   ],
   "source": [
    "full_ds = train_ds + test_ds + val_ds\n",
    "vocab = Vocabulary.from_instances(full_ds, tokens_to_add={\"tokens\": [\"[MASK]\"]},\n",
    "                                  max_vocab_size=config.max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build word to indices mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    # TODO: Speed up\n",
    "    with timer(\"Building character indexes\"):\n",
    "        word_id_to_char_idxs = []\n",
    "        freqs = []\n",
    "        for w, freq in word_freqs.items():\n",
    "            char_idxs = token_indexer.tokens_to_indices([Token(w)], None, \"tokens\")[\"tokens\"][0]\n",
    "            word_id_to_char_idxs.append(char_idxs)\n",
    "            freqs.append(freqs)\n",
    "        word_id_to_char_idxs = np.array(word_id_to_char_idxs)\n",
    "        freqs = np.array(freqs)\n",
    "\n",
    "    word_id_to_char_idxs = torch.LongTensor(word_id_to_char_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator, DataIterator\n",
    "iterator = BucketIterator(\n",
    "        batch_size=config.batch_size, \n",
    "        biggest_batch_first=config.testing,\n",
    "        sorting_keys=[(\"input\", \"num_tokens\")],\n",
    ")\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterator(train_ds))[\"input\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterator(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building token embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.char_encoder == \"cnn\":\n",
    "    from allennlp.modules.token_embedders.elmo_token_embedder import ElmoTokenEmbedder\n",
    "    from allennlp.modules.elmo import _ElmoCharacterEncoder\n",
    "\n",
    "    options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "    weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "    char_encoder = _ElmoCharacterEncoder(\n",
    "        options_file=options_file, \n",
    "        weight_file=weight_file,\n",
    "        requires_grad=True\n",
    "    )\n",
    "\n",
    "# char_encoder\n",
    "\n",
    "# sample_idxs = next(iterator(train_ds))[\"tokens\"][\"tokens\"]\n",
    "\n",
    "# char_encoder(sample_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.modeling import (BertConfig, BertForMaskedLM, \n",
    "                                              BertEncoder, BertPooler, BertOnlyMLMHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = BertConfig(\n",
    "        config.max_vocab_size, hidden_size=512, num_attention_heads=4,\n",
    "        num_hidden_layers=6, intermediate_size=512 * 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 512,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 2048,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 40000\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, temporarily use fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def get_fasttext_embeddings(model_path: str, vocab: Vocabulary):\n",
    "    prog_bar = tqdm(open(model_path, encoding=\"utf8\", errors='ignore'))\n",
    "    prog_bar.set_description(\"Loading embeddings\")\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in prog_bar\n",
    "                             if len(o)>100)\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "\n",
    "    embeddings = np.zeros((bert_config.vocab_size + 5, 300))\n",
    "    n_missing_tokens = 0\n",
    "    prog_bar = tqdm(vocab.get_index_to_token_vocabulary().items())\n",
    "    prog_bar.set_description(\"Creating matrix\")\n",
    "    for idx, token in prog_bar:\n",
    "        if idx == 0: continue # keep padding as all zeros\n",
    "        if idx == 1: continue # Treat unknown words as dropped words\n",
    "        if token == \"[MASK]\":\n",
    "            embeddings[idx, :] = np.random.randn(300) * 0.5\n",
    "        if token not in embeddings_index:\n",
    "            n_missing_tokens += 1\n",
    "            if n_missing_tokens < 10:\n",
    "                warnings.warn(f\"Token {token} not in embeddings: did you change preprocessing?\")\n",
    "            if n_missing_tokens == 10:\n",
    "                warnings.warn(f\"More than {n_missing_tokens} missing, supressing warnings\")\n",
    "        else:\n",
    "            embeddings[idx, :] = embeddings_index[token]\n",
    "    \n",
    "    if n_missing_tokens > 0:\n",
    "        warnings.warn(f\"{n_missing_tokens} in total are missing from embedding text file\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading embeddings: : 317458it [00:27, 11704.95it/s]\n",
      "/Users/keitakurita/.local/share/virtualenvs/NNforNLP-axlxMEpb/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "Creating matrix:  97%|█████████▋| 18206/18864 [00:00<00:00, 182058.44it/s]/Users/keitakurita/.local/share/virtualenvs/NNforNLP-axlxMEpb/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Token [MASK] not in embeddings: did you change preprocessing?\n",
      "Creating matrix: 100%|██████████| 18864/18864 [00:00<00:00, 178514.85it/s]\n",
      "/Users/keitakurita/.local/share/virtualenvs/NNforNLP-axlxMEpb/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: 1 in total are missing from embedding text file\n"
     ]
    }
   ],
   "source": [
    "ft_matrix = get_fasttext_embeddings(str(DATA_ROOT / \"ft_model.txt\"), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(x):\n",
    "    x.requires_grad = False\n",
    "    if hasattr(x, \"parameters\"):\n",
    "        for p in x.parameters: freeze(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedding(Embedding):\n",
    "    def __init__(self, num_embeddings, embedding_dim, bert_hidden_sz,\n",
    "                 freeze_embeddings=False, dropout=0.1, **kwargs):\n",
    "        super().__init__(num_embeddings, embedding_dim, **kwargs)\n",
    "        if freeze_embeddings:\n",
    "            freeze(self.weight)\n",
    "        self.position_embeddings = nn.Embedding(config.max_seq_len, \n",
    "                                                bert_hidden_sz)\n",
    "        self.linear = nn.Linear(embedding_dim, bert_hidden_sz,\n",
    "                                bias=False) # Transform dimensions\n",
    "        self.norm = LayerNorm(bert_hidden_sz)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        # We won't be using token types since we won't be predicting the next sentence\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = (torch.arange(seq_length, dtype=torch.long)\n",
    "                             .to(input_ids.device)\n",
    "                             .unsqueeze(0)\n",
    "                             .expand_as(input_ids))\n",
    "        word_embs = self.linear(super().forward(input_ids))\n",
    "        position_embs = self.position_embeddings(position_ids)\n",
    "        return self.do(self.norm(word_embs + position_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_embs = CustomEmbedding(bert_config.vocab_size + 5, \n",
    "                              300,\n",
    "                              bert_config.hidden_size,\n",
    "                              weight=torch.FloatTensor(ft_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomEmbedding(\n",
       "  (position_embeddings): Embedding(512, 512)\n",
       "  (linear): Linear(in_features=300, out_features=512, bias=False)\n",
       "  (norm): LayerNorm()\n",
       "  (do): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encoder = BertEncoder(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBert(nn.Module):\n",
    "    def __init__(self, embeddings, encoder):\n",
    "        super().__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.encoder = encoder\n",
    "        \n",
    "    def forward(self, input_ids, \n",
    "                token_type_ids=None, \n",
    "                attention_mask=None):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "        \n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
    "        encoded_layers = self.encoder(embedding_output,\n",
    "                                      extended_attention_mask,\n",
    "                                      output_all_encoded_layers=True)\n",
    "        return encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMLMPooler(nn.Module):\n",
    "    def forward(self, x: List[torch.FloatTensor]) -> torch.FloatTensor:\n",
    "        return x[-1] # return final layer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = CustomBert(sample_embs, bert_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "class BertCustomLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config, embedding):\n",
    "        super().__init__()\n",
    "        # Projections\n",
    "        self.dense = nn.Linear(config.hidden_size, embedding.shape[1])\n",
    "        self.transform_act_fn = gelu\n",
    "        self.LayerNorm = LayerNorm(embedding.shape[1])\n",
    "        \n",
    "        # Predictions\n",
    "        self.decoder = nn.Linear(embedding.size(1), embedding.size(0), \n",
    "                                 bias=False)\n",
    "        self.decoder.weight = embedding\n",
    "        self.bias = nn.Parameter(torch.zeros(embedding.size(0)))\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        preds = self.decoder(hidden_states) + self.bias\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mlm_head = BertCustomLMPredictionHead(bert_config, sample_embs.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = nn.Sequential(\n",
    "    bert_model,\n",
    "    BertMLMPooler(),\n",
    "    bert_mlm_head,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masker(nn.Module):\n",
    "    # TODO: Implement copying\n",
    "    def __init__(self, vocab: Vocabulary, mask_rate: float=0.15):\n",
    "        super().__init__()\n",
    "        self.mask_id = vocab.get_token_index(\"[MASK]\")\n",
    "        self.mask_rate = mask_rate\n",
    "\n",
    "    def forward(self, x: torch.LongTensor) -> torch.LongTensor:\n",
    "        mask = torch.ones(x.shape, dtype=torch.uint8).bernoulli(1 - self.mask_rate)\n",
    "        return x.masked_fill(mask, self.mask_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLM(Model):\n",
    "    def __init__(self, vocab: Vocabulary, model: nn.Module):\n",
    "        super().__init__(vocab)\n",
    "        self.masker = Masker(vocab)\n",
    "        self.model = model\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, input: TensorDict, \n",
    "                output: TensorDict, **kwargs) -> TensorDict:\n",
    "        x = self.masker(input[\"tokens\"])\n",
    "        logits = self.model(x)\n",
    "        out_dict = {\"loss\": self.loss(logits.view((-1, logits.size(-1))),\n",
    "                                                  output[\"tokens\"].view((-1, )))}\n",
    "        out_dict[\"logits\"] = logits\n",
    "        return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm = MaskedLM(vocab, custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = masked_lm(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(38.7347, grad_fn=<NllLossBackward>),\n",
       " 'logits': tensor([[[ 0.0000,  0.0000,  0.6921,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  1.9607,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -1.2008,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  2.2032,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.2016,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.8598,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000,  0.3411,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  2.5390,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -1.2102,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  2.4451,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  1.0797,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0840,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000, -1.3008,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.8785,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -1.2621,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  2.2251,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.7884,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.8256,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0000,  0.0000,  1.3503,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  1.7572,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -1.2372,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  2.0143,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  1.1388,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.8187,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000, -0.7652,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  3.0147,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -1.7334,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  1.9233,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.7226,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.2865,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0000,  0.0000, -0.3453,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  2.1490,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -1.0453,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  3.0581,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  1.0290,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.6998,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2019 16:08:53 - WARNING - allennlp.training.trainer -   You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n"
     ]
    }
   ],
   "source": [
    "from allennlp.training import Trainer\n",
    "\n",
    "optimizer = torch.optim.Adam(masked_lm.parameters(), lr=config.lr)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=masked_lm,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    serialization_dir=None,\n",
    "    cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "    num_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2019 16:08:53 - INFO - allennlp.training.trainer -   Beginning training.\n",
      "02/23/2019 16:08:53 - INFO - allennlp.training.trainer -   Epoch 0/0\n",
      "02/23/2019 16:08:53 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 5675.966464\n",
      "02/23/2019 16:08:53 - INFO - allennlp.training.trainer -   Training\n",
      "loss: 9.9748 ||: 100%|██████████| 63/63 [06:00<00:00,  2.77s/it] \n",
      "02/23/2019 16:14:53 - INFO - allennlp.training.trainer -   Validating\n",
      "loss: 7.4051 ||: 100%|██████████| 63/63 [01:33<00:00,  5.44s/it]\n",
      "02/23/2019 16:16:26 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/23/2019 16:16:26 - INFO - allennlp.training.trainer -   cpu_memory_MB |  5675.966  |       N/A\n",
      "02/23/2019 16:16:26 - INFO - allennlp.training.trainer -   loss          |     9.975  |     7.405\n",
      "02/23/2019 16:16:26 - INFO - allennlp.training.trainer -   Epoch duration: 00:07:33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'peak_cpu_memory_MB': 5675.966464,\n",
       " 'training_duration': '00:07:33',\n",
       " 'training_start_epoch': 0,\n",
       " 'training_epochs': 0,\n",
       " 'epoch': 0,\n",
       " 'training_loss': 9.974837212335496,\n",
       " 'training_cpu_memory_MB': 5675.966464,\n",
       " 'validation_loss': 7.405061123863099,\n",
       " 'best_epoch': 0,\n",
       " 'best_validation_loss': 7.405061123863099}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Sampling Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different decoder (TODO: Enable sharing of parameters)\n",
    "# char_decoder = _ElmoCharacterEncoder(\n",
    "#     options_file=options_file, \n",
    "#     weight_file=weight_file,\n",
    "#     requires_grad=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCorrection(nn.Module):\n",
    "    \"\"\"From the paper `Exploring the Limitations of Language Modeling`\"\"\"\n",
    "    def __init__(self, hidden_sz: int, bottleneck_sz: int=128):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(hidden_sz, bottleneck_sz)\n",
    "        \n",
    "    def forward(self, h: torch.FloatTensor, \n",
    "                corr: torch.FloatTensor):\n",
    "        x = self.l1(h)\n",
    "        return x @ corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Implement importance sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unigram_noise(freq):\n",
    "    \"\"\"build the unigram noise from a list of frequency\n",
    "    Parameters:\n",
    "        freq: a tensor of #occurrences of the corresponding index\n",
    "    Return:\n",
    "        unigram_noise: a torch.Tensor with size ntokens,\n",
    "        elements indicate the probability distribution\n",
    "    \"\"\"\n",
    "    total = freq.sum()\n",
    "    noise = freq / total\n",
    "    assert abs(noise.sum() - 1) < 0.001\n",
    "    return noise ** 0.75 # slight modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorical(probs=torch.rand(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportanceSamplingLoss(nn.Module):\n",
    "    def __init__(self, embedding_generator: nn.Module,\n",
    "                 probs: np.ndarray, k=10):\n",
    "        super().__init__()\n",
    "        self.embedding_generator = embedding_generator\n",
    "        self.sampler = Categorical(probs=probs)\n",
    "        self._loss_func = nn.CrossEntropyLoss()\n",
    "        self.k = k\n",
    "    \n",
    "    def get_negative_samples(self, bs) -> torch.LongTensor:\n",
    "        neg = self.sampler.sample((bs, self.k, ))\n",
    "        return neg\n",
    "    \n",
    "    def get_embeddings(self, idxs: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Converts indexes into vectors\"\"\"\n",
    "        return self.embedding_generator(idxs, None) # TODO: Implement general case\n",
    "    \n",
    "    def forward(self, y: torch.LongTensor, tgt):\n",
    "        \"\"\"\n",
    "        Expects input of shape\n",
    "        y: (batch * seq, feature_sz)\n",
    "        tgt: (batch * seq, )\n",
    "        \"\"\"\n",
    "        bs = y.size(0)\n",
    "        neg_samples = self.get_negative_samples(bs)\n",
    "        idxs = torch.cat([tgt.unsqueeze(1), neg_samples], dim=1)\n",
    "        # TODO: More efficient implementation? (Ask TAs)\n",
    "        dot_prods = torch.bmm(y.unsqueeze(1), \n",
    "                              self.get_embeddings(idxs).transpose(1, 2)).squeeze(1)\n",
    "        return self._loss_func(dot_prods, torch.zeros(bs, dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn((3, 7, 512)).view((-1, 512))\n",
    "tgt = torch.randint(100, (3, 7)).view((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = cat.sample((y.size(0), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.cat([tgt.unsqueeze(1), neg_samples], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11, 512])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embs(idxs, None).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 512])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(y.unsqueeze(1), sample_embs(idxs, None).transpose(1, 2)).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ImportanceSamplingLoss(\n",
    "    sample_embs, probs=torch.rand(100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.9522, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(y, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
