{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dependencies"
    ]
   },
   "outputs": [],
   "source": [
    "depends_on = [\n",
    "    \"preproc_jigsaw\",\n",
    "    \"jigsaw_create_augmented_data\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for seamlessly running on colab\n",
    "import os\n",
    "os.environ[\"IS_COLAB\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ[\"IS_COLAB\"] == \"True\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ \"$IS_COLAB\" = \"True\" ]; then\n",
    "    pip install git+https://github.com/facebookresearch/fastText.git\n",
    "    pip install torch\n",
    "    pip install torchvision\n",
    "    pip install allennlp\n",
    "    pip install dnspython\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "import functools\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "def get_ref_free_exc_info():\n",
    "    \"Free traceback from references to locals/globals to avoid circular reference leading to gc.collect() unable to reclaim memory\"\n",
    "    type, val, tb = sys.exc_info()\n",
    "    traceback.clear_frames(tb)\n",
    "    return (type, val, tb)\n",
    "\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = get_ref_free_exc_info() # must!\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# for papermill\n",
    "testing = True\n",
    "debugging = False\n",
    "seed = 1\n",
    "computational_batch_size = 256\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "epochs = 1\n",
    "hidden_sz = 64\n",
    "dataset = \"jigsaw\"\n",
    "n_classes = 6\n",
    "max_seq_len = 512\n",
    "download_data = False\n",
    "ft_model_path = \"../data/jigsaw/ft_model.bin\"\n",
    "max_vocab_size = 300000\n",
    "dropoute = 0.5\n",
    "val_ratio = 0.05\n",
    "use_augmented = False\n",
    "mixup_ratio = 0.2\n",
    "bias_init = True\n",
    "neg_splits = 3\n",
    "model_type = \"standard\"\n",
    "run_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Can we make this play better with papermill?\n",
    "config = Config(\n",
    "    testing=testing,\n",
    "    debugging=debugging,\n",
    "    seed=seed,\n",
    "    computational_batch_size=computational_batch_size,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    epochs=epochs,\n",
    "    hidden_sz=hidden_sz,\n",
    "    dataset=dataset,\n",
    "    n_classes=n_classes,\n",
    "    max_seq_len=max_seq_len, # necessary to limit memory usage\n",
    "    ft_model_path=ft_model_path,\n",
    "    max_vocab_size=max_vocab_size,\n",
    "    dropoute=dropoute,\n",
    "    val_ratio=val_ratio,\n",
    "    use_augmented=use_augmented,\n",
    "    bias_init=bias_init,\n",
    "    neg_splits=neg_splits,\n",
    "    model_type=model_type,\n",
    "    mixup_ratio=mixup_ratio,\n",
    "    run_id=run_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common.checks import ConfigurationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model_type != \"standard\" and \"bert\" not in config.model_type and \"elmo\" not in config.model_type:\n",
    "    raise ConfigurationError(f\"Invalid model type {config.model_type} given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "RUN_ID = config.run_id if config.run_id is not None else now.strftime(\"%m_%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ[\"IS_COLAB\"] != \"True\":\n",
    "    DATA_ROOT = Path(\"../data\") / config.dataset\n",
    "else:\n",
    "    DATA_ROOT = Path(\"./gdrive/My Drive/Colab_Workspace/Colab Notebooks/data\") / config.dataset\n",
    "    config.ft_model_path = str(DATA_ROOT / \"ft_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {DATA_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "if download_data:\n",
    "    if config.val_ratio > 0.0:\n",
    "        fnames = [\"train_wo_val.csv\", \"test_proced.csv\", \"val.csv\", \"ft_model.bin\"]\n",
    "    else:\n",
    "        fnames = [\"train.csv\", \"test_proced.csv\", \"ft_model.bin\"]\n",
    "    if config.use_augmented: fnames.append(\"train_extra.csv\")\n",
    "    for fname in fnames:\n",
    "        if not (DATA_ROOT / fname).exists():\n",
    "            print(subprocess.Popen([f\"aws s3 cp s3://nnfornlp/raw_data/jigsaw/{fname} {str(DATA_ROOT)}\"],\n",
    "                                   shell=True, stdout=subprocess.PIPE).stdout.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {DATA_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed manually to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.dataset_readers import DatasetReader, StanfordSentimentTreeBankDatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_registry = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register(name: str):\n",
    "    def dec(x: Callable):\n",
    "        reader_registry[name] = x\n",
    "        return x\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\",\n",
    "              \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "from enum import IntEnum\n",
    "ColIdx = IntEnum('ColIdx', [(x.upper(), i) for i, x in enumerate(label_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import TextField, SequenceLabelField, LabelField, MetadataField, ArrayField\n",
    "\n",
    "@register(\"jigsaw\")\n",
    "class JigsawDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None, # TODO: Handle mapping from BERT\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[Token], id: str,\n",
    "                         labels: np.ndarray) -> Instance:\n",
    "        sentence_field = TextField([Token(x) for x in tokens],\n",
    "                                   self.token_indexers)\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "        \n",
    "        id_field = MetadataField(id)\n",
    "        fields[\"id\"] = id_field\n",
    "        \n",
    "        meta_field = MetadataField({\"lengths\": np.array([len(t) for t in tokens])})\n",
    "        fields[\"meta\"] = meta_field\n",
    "        \n",
    "        label_field = ArrayField(array=labels)\n",
    "        fields[\"label\"] = label_field\n",
    "\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                self.tokenizer(row[\"comment_text\"]),\n",
    "                row[\"id\"], row[label_cols].values,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare token handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers import WordpieceIndexer, SingleIdTokenIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"standard\":\n",
    "    from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
    "    token_indexer = SingleIdTokenIndexer(\n",
    "        lowercase_tokens=False,  # don't lowercase by default\n",
    "    )\n",
    "    def tokenizer(x: str):\n",
    "        return [w.text for w in\n",
    "                SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words(x)[:config.max_seq_len]]\n",
    "elif \"elmo\" in model_type:\n",
    "    from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer\n",
    "    token_indexer = ELMoTokenCharactersIndexer()\n",
    "    def tokenizer(x: str):\n",
    "        return [w.text for w in\n",
    "                SpacyWordSplitter(language='en_core_web_sm', pos_tags=False).split_words(x)[:config.max_seq_len]]\n",
    "elif \"bert\" in model_type:\n",
    "    from allennlp.data.token_indexers import PretrainedBertIndexer\n",
    "    token_indexer = PretrainedBertIndexer(\n",
    "        pretrained_model=config.model_type,\n",
    "        max_pieces=config.max_seq_len,\n",
    "        do_lowercase=True,\n",
    "     )\n",
    "    # apparently we need to truncate the sequence here, which is a stupid design decision\n",
    "    def tokenizer(s: str):\n",
    "        return token_indexer.wordpiece_tokenizer(s)[:config.max_seq_len - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = JigsawDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer}\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.val_ratio > 0.0:\n",
    "    train_ds, val_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train_wo_val.csv\",\n",
    "                                                                              \"val.csv\",\n",
    "                                                                              \"test_proced.csv\"])\n",
    "else:\n",
    "    train_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train.csv\",\n",
    "                                                                      \"test_proced.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_augmented:\n",
    "    # TODO: Handle data leak for validation!\n",
    "    train_aug_ds = reader.read(DATA_ROOT / \"train_extra_interpolated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.val_ratio > 0.0:\n",
    "    train_labels = pd.read_csv(DATA_ROOT / \"train_wo_val.csv\")[label_cols].values\n",
    "else:\n",
    "    train_labels = pd.read_csv(DATA_ROOT / \"train.csv\")[label_cols].values\n",
    "if config.testing: train_labels = train_labels[:len(train_ds), :]\n",
    "if config.use_augmented:\n",
    "    train_aux_labels = pd.read_csv(DATA_ROOT / \"train_extra.csv\")[label_cols].values\n",
    "    if config.testing: train_aux_labels = train_aux_labels[:len(train_ds), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary.from_instances(train_ds, max_vocab_size=config.max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator, DataIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class Sampler:\n",
    "    def sample(self, ds: List[Instance]) -> List[Instance]:\n",
    "        return ds\n",
    "\n",
    "class BiasedSampler(Sampler):\n",
    "    def __init__(self, mask: np.ndarray, n_splits: int):\n",
    "        self.mask = mask\n",
    "        self.n_splits = n_splits\n",
    "        self.pos = np.where(self.mask)[0]\n",
    "        self.neg = np.where(~self.mask)[0]\n",
    "        self._n_splits_iterated = 0\n",
    "        \n",
    "    def sample(self, ds: List[Instance]):\n",
    "        if self._n_splits_iterated % self.n_splits == 0:\n",
    "            self.folds = KFold(n_splits=self.n_splits).split(self.neg)\n",
    "        _, neg_idxs = next(self.folds)\n",
    "        \n",
    "        p = np.random.permutation(len(self.pos) + len(neg_idxs))\n",
    "        smpl = np.r_[self.pos, self.neg[neg_idxs]][p]\n",
    "        \n",
    "        self._n_splits_iterated += 1\n",
    "        return [ds[i] for i in smpl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoredSampler:\n",
    "    def __init__(self, mask: np.ndarray, ratio: float):\n",
    "        self.mask = mask\n",
    "        self.ratio = ratio\n",
    "        self.n_samples = int(len(self.tgt) * self.ratio)\n",
    "        self.score = mask.astype(\"int\")\n",
    "    \n",
    "    def set_score(self, score: np.ndarray):\n",
    "        assert len(score) == len(self.tgt)\n",
    "        self.score = score\n",
    "    \n",
    "    def sample(self, ds: List[Instance]):\n",
    "        \"\"\"Sample top n targets sorted by score descending\"\"\"\n",
    "        smpl = np.arange(len(self.mask))[np.argsort(-self.score)][:self.n_samples]\n",
    "        return [ds[i] for i in smpl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.common.util import lazy_groups_of, add_noise_to_dict_values\n",
    "from allennlp.data.dataset import Batch\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.iterators.data_iterator import DataIterator\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "TensorDict = Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]  # pylint: disable=invalid-name\n",
    "\n",
    "def sort_by_padding(instances: List[Instance],\n",
    "                    sorting_keys: List[Tuple[str, str]],  # pylint: disable=invalid-sequence-index\n",
    "                    vocab: Vocabulary,\n",
    "                    padding_noise: float = 0.0) -> List[Instance]:\n",
    "    \"\"\"\n",
    "    Sorts the instances by their padding lengths, using the keys in\n",
    "    ``sorting_keys`` (in the order in which they are provided).  ``sorting_keys`` is a list of\n",
    "    ``(field_name, padding_key)`` tuples.\n",
    "    \"\"\"\n",
    "    instances_with_lengths = []\n",
    "    for instance in instances:\n",
    "        # Make sure instance is indexed before calling .get_padding\n",
    "        instance.index_fields(vocab)\n",
    "        padding_lengths = cast(Dict[str, Dict[str, float]], instance.get_padding_lengths())\n",
    "        if padding_noise > 0.0:\n",
    "            noisy_lengths = {}\n",
    "            for field_name, field_lengths in padding_lengths.items():\n",
    "                noisy_lengths[field_name] = add_noise_to_dict_values(field_lengths, padding_noise)\n",
    "            padding_lengths = noisy_lengths\n",
    "        instance_with_lengths = ([padding_lengths[field_name][padding_key]\n",
    "                                  for (field_name, padding_key) in sorting_keys],\n",
    "                                 instance)\n",
    "        instances_with_lengths.append(instance_with_lengths)\n",
    "    instances_with_lengths.sort(key=lambda x: x[0])\n",
    "    return [instance_with_lengths[-1] for instance_with_lengths in instances_with_lengths]\n",
    "\n",
    "class CustomBucketIterator(DataIterator):\n",
    "    \"\"\"\n",
    "    An iterator which by default, pads batches with respect to the maximum input lengths `per\n",
    "    batch`. Additionally, you can provide a list of field names and padding keys which the dataset\n",
    "    will be sorted by before doing this batching, causing inputs with similar length to be batched\n",
    "    together, making computation more efficient (as less time is wasted on padded elements of the\n",
    "    batch).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sorting_keys : List[Tuple[str, str]]\n",
    "        To bucket inputs into batches, we want to group the instances by padding length, so that we\n",
    "        minimize the amount of padding necessary per batch. In order to do this, we need to know\n",
    "        which fields need what type of padding, and in what order.\n",
    "\n",
    "        For example, ``[(\"sentence1\", \"num_tokens\"), (\"sentence2\", \"num_tokens\"), (\"sentence1\",\n",
    "        \"num_token_characters\")]`` would sort a dataset first by the \"num_tokens\" of the\n",
    "        \"sentence1\" field, then by the \"num_tokens\" of the \"sentence2\" field, and finally by the\n",
    "        \"num_token_characters\" of the \"sentence1\" field.  TODO(mattg): we should have some\n",
    "        documentation somewhere that gives the standard padding keys used by different fields.\n",
    "    padding_noise : float, optional (default=.1)\n",
    "        When sorting by padding length, we add a bit of noise to the lengths, so that the sorting\n",
    "        isn't deterministic.  This parameter determines how much noise we add, as a percentage of\n",
    "        the actual padding value for each instance.\n",
    "    biggest_batch_first : bool, optional (default=False)\n",
    "        This is largely for testing, to see how large of a batch you can safely use with your GPU.\n",
    "        This will let you try out the largest batch that you have in the data `first`, so that if\n",
    "        you're going to run out of memory, you know it early, instead of waiting through the whole\n",
    "        epoch to find out at the end that you're going to crash.\n",
    "\n",
    "        Note that if you specify ``max_instances_in_memory``, the first batch will only be the\n",
    "        biggest from among the first \"max instances in memory\" instances.\n",
    "    batch_size : int, optional, (default = 32)\n",
    "        The size of each batch of instances yielded when calling the iterator.\n",
    "    instances_per_epoch : int, optional, (default = None)\n",
    "        See :class:`BasicIterator`.\n",
    "    max_instances_in_memory : int, optional, (default = None)\n",
    "        See :class:`BasicIterator`.\n",
    "    maximum_samples_per_batch : ``Tuple[str, int]``, (default = None)\n",
    "        See :class:`BasicIterator`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 sorting_keys: List[Tuple[str, str]],\n",
    "                 padding_noise: float = 0.1,\n",
    "                 biggest_batch_first: bool = False,\n",
    "                 batch_size: int = 32,\n",
    "                 instances_per_epoch: int = None,\n",
    "                 max_instances_in_memory: int = None,\n",
    "                 cache_instances: bool = False,\n",
    "                 track_epoch: bool = False,\n",
    "                 maximum_samples_per_batch: Tuple[str, int] = None,\n",
    "                 negative_sample_rate: Optional[int]=None,\n",
    "                 sampler: Sampler=None) -> None:\n",
    "        if not sorting_keys:\n",
    "            raise ConfigurationError(\"BucketIterator requires sorting_keys to be specified\")\n",
    "\n",
    "        super().__init__(cache_instances=cache_instances,\n",
    "                         track_epoch=track_epoch,\n",
    "                         batch_size=batch_size,\n",
    "                         instances_per_epoch=instances_per_epoch,\n",
    "                         max_instances_in_memory=max_instances_in_memory,\n",
    "                         maximum_samples_per_batch=maximum_samples_per_batch)\n",
    "        self._sorting_keys = sorting_keys\n",
    "        self._padding_noise = padding_noise\n",
    "        self._biggest_batch_first = biggest_batch_first\n",
    "        if sampler is not None:\n",
    "            self.sampler = Sampler()\n",
    "        else:\n",
    "            self.sampler = sampler\n",
    "\n",
    "    @overrides\n",
    "    def _create_batches(self, instances: Iterable[Instance], shuffle: bool) -> Iterable[Batch]:\n",
    "        for instance_list in self._memory_sized_lists(self.sampler.sample(instances)):\n",
    "            instance_list = sort_by_padding(instance_list,\n",
    "                                            self._sorting_keys,\n",
    "                                            self.vocab,\n",
    "                                            self._padding_noise)\n",
    "            batches = []\n",
    "            excess: Deque[Instance] = deque()\n",
    "            for batch_instances in lazy_groups_of(iter(instance_list), self._batch_size):\n",
    "                for possibly_smaller_batches in self._ensure_batch_is_sufficiently_small(batch_instances, excess):\n",
    "                    batches.append(Batch(possibly_smaller_batches))\n",
    "            if excess:\n",
    "                batches.append(Batch(excess))\n",
    "\n",
    "            move_to_front = self._biggest_batch_first and len(batches) > 1\n",
    "            if move_to_front:\n",
    "                # We'll actually pop the last _two_ batches, because the last one might not be full.\n",
    "                last_batch = batches.pop()\n",
    "                penultimate_batch = batches.pop()\n",
    "            if shuffle:\n",
    "                # NOTE: if shuffle is false, the data will still be in a different order\n",
    "                # because of the bucket sorting.\n",
    "                random.shuffle(batches)\n",
    "            if move_to_front:\n",
    "                batches.insert(0, penultimate_batch)\n",
    "                batches.insert(0, last_batch)\n",
    "\n",
    "            yield from batches\n",
    "        \n",
    "        def __call__(self, instances: Iterable[Instance],\n",
    "                     num_epochs: int=None, shuffle: bool=True) -> Iterator[TensorDict]:\n",
    "            yield from super().__call__(instances, \n",
    "                                        num_epochs=num_epochs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Allow for customization\n",
    "if config.neg_splits > 1:\n",
    "    if config.use_augmented:\n",
    "        full_trn_labels = np.concatenate([train_labels, train_aux_labels], axis=0)\n",
    "    else:\n",
    "        full_trn_labels = train_labels\n",
    "    sampler = BiasedSampler(full_trn_labels.sum(1) >= 1,\n",
    "                            config.neg_splits)\n",
    "else:\n",
    "    sampler = Sampler()\n",
    "iterator = CustomBucketIterator(\n",
    "    batch_size=config.batch_size, \n",
    "    biggest_batch_first=True,\n",
    "    sorting_keys=[(\"tokens\", \"num_tokens\")],\n",
    "    sampler=sampler,\n",
    ")\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(iterator(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"tokens\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"tokens\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.token_embedders.bert_token_embedder import BertEmbedder, PretrainedBertEmbedder\n",
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.modules.stacked_bidirectional_lstm import StackedBidirectionalLstm\n",
    "from allennlp.nn.util import get_text_field_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, inp_sz, dim=1, eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.inp_sz, self.dim, self.eps = inp_sz, dim, eps\n",
    "        self.l1 = nn.Linear(inp_sz, inp_sz)\n",
    "        nn.init.xavier_uniform_(self.l1.weight.data)\n",
    "        nn.init.zeros_(self.l1.bias.data)\n",
    "        \n",
    "        vw = torch.zeros(inp_sz, 1)\n",
    "        nn.init.xavier_uniform_(vw)        \n",
    "        self.vw = nn.Parameter(vw)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        e = torch.tanh(self.l1(x))\n",
    "        e = torch.einsum(\"bij,jk->bi\", [e, self.vw])            \n",
    "        a = torch.exp(e)\n",
    "        \n",
    "        if mask is not None: a = a.masked_fill(mask, 0)\n",
    "\n",
    "        a = a / (torch.sum(a, dim=self.dim, keepdim=True) + self.eps)\n",
    "\n",
    "        weighted_input = x * a.unsqueeze(-1)\n",
    "        return torch.sum(weighted_input, dim=1), a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_weights(gru: nn.GRU):\n",
    "    \"\"\"Applies orthogonal and xavier uniform initialization according to best practices\"\"\"\n",
    "    for nm, param in gru.named_parameters():\n",
    "        if \"weight_hh\" in nm:\n",
    "            nn.init.orthogonal_(param.data)\n",
    "        elif \"weight_ih\" in nm:\n",
    "            nn.init.xavier_uniform_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRUAttentionEncoder(Seq2VecEncoder):\n",
    "    def __init__(self, embed_sz: int, hidden_sz: int, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embed_sz = embed_sz\n",
    "        self.hidden_sz = hidden_sz\n",
    "        self.gru = nn.GRU(self.embed_sz, self.hidden_sz,\n",
    "                          num_layers=num_layers, bidirectional=True)\n",
    "        init_gru_weights(self.gru)\n",
    "        self.attention = Attention(self.hidden_sz * 2, dim=1)\n",
    "        \n",
    "    @overrides\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self.embed_sz\n",
    "    \n",
    "    @overrides\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self.hidden_sz * 2\n",
    "    \n",
    "    @overrides\n",
    "    def forward(self, x: torch.tensor, \n",
    "                mask: Optional[torch.tensor]=None) -> torch.tensor:\n",
    "        x, _ = self.gru(x, None)\n",
    "        x, _ = self.attention(x, mask=mask == 0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.metrics import CategoricalAccuracy, BooleanAccuracy, Metric\n",
    "\n",
    "def prod(x: Iterable):\n",
    "    acc = 1\n",
    "    for v in x: acc *= v\n",
    "    return acc\n",
    "\n",
    "class MultilabelAccuracy(Metric):\n",
    "    def __init__(self, thres=0.5):\n",
    "        self.thres = 0.5\n",
    "        self.correct_count = 0\n",
    "        self.total_count = 0\n",
    "    \n",
    "    def __call__(self, logits: torch.FloatTensor, \n",
    "                 t: torch.LongTensor) -> float:\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        t = t.detach().cpu().numpy()\n",
    "        cc = ((logits >= self.thres) == t).sum()\n",
    "        tc = prod(logits.shape)\n",
    "        self.correct_count += cc\n",
    "        self.total_count += tc\n",
    "        return cc / tc\n",
    "    \n",
    "    def get_metric(self, reset: bool=False):\n",
    "        acc = self.correct_count / self.total_count\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return acc\n",
    "    \n",
    "    @overrides\n",
    "    def reset(self):\n",
    "        self.correct_count = 0\n",
    "        self.total_count = 0\n",
    "    \n",
    "class MultilabelCrossEntropyLoss(nn.Module):\n",
    "    def forward(self, lgt, tgt: torch.LongTensor):\n",
    "        neg_abs = -lgt.abs()\n",
    "        loss = lgt.clamp(min=0) - lgt * tgt.float() + (1 + neg_abs.exp()).log()\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.nn.util import move_to_device, has_tensor\n",
    "\n",
    "def permute(obj, p: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Given a structure (possibly) containing Tensors on the CPU,\n",
    "    permute all the Tensors\n",
    "    \"\"\"\n",
    "    if not has_tensor(obj):\n",
    "        return obj\n",
    "    elif isinstance(obj, torch.Tensor):\n",
    "        return obj[p]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: permute(value, p) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [permute(item, p) for item in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple([permute(item, p) for item in obj])\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from torch.distributions.beta import Beta\n",
    "\n",
    "class BaselineModel(Model):\n",
    "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 out_sz: int=config.n_classes,\n",
    "                 multilabel: bool=True, mixup_alpha: int=0.2):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
    "        self.multilabel = multilabel\n",
    "        self.lambda_sampler = Beta(torch.tensor([mixup_alpha]), torch.tensor([mixup_alpha]))\n",
    "        # TODO: Handle multiclass case\n",
    "        if self.multilabel:\n",
    "            self.accuracy = MultilabelAccuracy()\n",
    "            self.per_label_acc = {c: MultilabelAccuracy() for c in label_cols}\n",
    "            self.loss = MultilabelCrossEntropyLoss()\n",
    "        else:\n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "            self.accuracy = CategoricalAccuracy()\n",
    "\n",
    "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
    "                label: torch.Tensor, **meta) -> torch.Tensor:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        state = self.encoder(embeddings, mask)\n",
    "        class_logits = self.projection(state)\n",
    "        \n",
    "        output = {\"class_logits\": class_logits}\n",
    "\n",
    "        output[\"accuracy\"] = self.accuracy(class_logits, label)\n",
    "        output[\"loss\"] = self.loss(class_logits, label)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def mixup(self, tokens: Dict[str, torch.Tensor],\n",
    "              label: torch.Tensor, **meta) -> TensorDict:\n",
    "        # generate new tokens and labels\n",
    "        bs = label.size(0)\n",
    "        shuf = torch.randperm(bs).to(label.device)\n",
    "        tokens2 = permute(tokens, shuf)\n",
    "        labels2 = permute(label, shuf)\n",
    "        # TODO: Think of how to handle this masking intelligently\n",
    "        mask1, mask2 = (get_text_field_mask(t) for t in (tokens, tokens2))\n",
    "        embs1, embs2 = (self.word_embeddings(t) for t in (tokens, tokens2))\n",
    "        # interpolate\n",
    "        ratios = self.lambda_sampler.sample((bs, 1)).to(label.device)\n",
    "        embs = ratios * embs1 + (1-ratios) * embs2\n",
    "        label = ratios * label + (1-ratios) * labels2\n",
    "        \n",
    "        # remaining process is the same\n",
    "        state = self.encoder(embs, mask1 * mask2) # TODO: Handle masking\n",
    "        class_logits = self.projection(state)\n",
    "        \n",
    "        output = {\"loss\": self.loss(class_logits, label)}\n",
    "        return output\n",
    "    \n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        return {\"accuracy\": self.accuracy.get_metric(reset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText\n",
    "\n",
    "def get_fasttext_embeddings(model_path: str, vocab: Vocabulary):\n",
    "    vocab_size = min(vocab.get_vocab_size(), config.max_vocab_size)\n",
    "    ft_model = fastText.load_model(config.ft_model_path)\n",
    "    embedding_dim = ft_model.get_dimension()\n",
    "\n",
    "    # register parameters\n",
    "    config.set(\"vocab_size\", vocab_size)\n",
    "    config.set(\"embedding_dim\", embedding_dim)\n",
    "    \n",
    "    embeddings = np.zeros((vocab_size + 5, embedding_dim))\n",
    "    for idx, token in vocab.get_index_to_token_vocabulary().items():\n",
    "        embeddings[idx, :] = ft_model.get_word_vector(token)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\"Loading embeddings\"):\n",
    "    embedding_weights = get_fasttext_embeddings(config.ft_model_path, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedding(Embedding):\n",
    "    def __init__(self, num_embeddings, embedding_dim,\n",
    "                 padding_index=None, max_norm=None,\n",
    "                 weight=None, dropout=0., scale=None):\n",
    "        super().__init__(num_embeddings, embedding_dim)\n",
    "        self.dropout = dropout\n",
    "        self.scale = scale\n",
    "        self.padding_idx = padding_index\n",
    "        self.embed = Embedding(num_embeddings, embedding_dim,\n",
    "                               padding_index=padding_index, max_norm=max_norm,\n",
    "                               weight=weight)\n",
    "    \n",
    "    def forward(self, words):\n",
    "        weight = self.embed.weight\n",
    "        if self.dropout > 0.0 and self.training:\n",
    "            mask = self.embed.weight.data.new().resize_((weight.size(0), 1)).bernoulli_(1 - self.dropout).expand_as(weight) / (1 - self.dropout)\n",
    "            masked_embed_weight = mask * weight\n",
    "        else:\n",
    "            masked_embed_weight = weight\n",
    "        if self.scale:\n",
    "            masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n",
    "\n",
    "        padding_idx = self.padding_idx\n",
    "        if padding_idx is None:\n",
    "            padding_idx = -1\n",
    "\n",
    "        X = torch.nn.functional.embedding(words, masked_embed_weight,\n",
    "            padding_idx, self.embed.max_norm, self.embed.norm_type,\n",
    "            self.embed.scale_grad_by_freq, self.embed.sparse\n",
    "          )\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common import Params\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules.text_field_embedders.text_field_embedder import TextFieldEmbedder\n",
    "from allennlp.modules.time_distributed import TimeDistributed\n",
    "from allennlp.modules.token_embedders.token_embedder import TokenEmbedder\n",
    "\n",
    "class CustomTextFieldEmbedder(TextFieldEmbedder):\n",
    "    \"\"\"\n",
    "    This is a ``TextFieldEmbedder`` that wraps a collection of :class:`TokenEmbedder` objects.  Each\n",
    "    ``TokenEmbedder`` embeds or encodes the representation output from one\n",
    "    :class:`~allennlp.data.TokenIndexer`.  As the data produced by a\n",
    "    :class:`~allennlp.data.fields.TextField` is a dictionary mapping names to these\n",
    "    representations, we take ``TokenEmbedders`` with corresponding names.  Each ``TokenEmbedders``\n",
    "    embeds its input, and the result is concatenated in an arbitrary order.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    token_embedders : ``Dict[str, TokenEmbedder]``, required.\n",
    "        A dictionary mapping token embedder names to implementations.\n",
    "        These names should match the corresponding indexer used to generate\n",
    "        the tensor passed to the TokenEmbedder.\n",
    "    embedder_to_indexer_map : ``Dict[str, List[str]]``, optional, (default = None)\n",
    "        Optionally, you can provide a mapping between the names of the TokenEmbedders\n",
    "        that you are using to embed your TextField and an ordered list of indexer names\n",
    "        which are needed for running it. In most cases, your TokenEmbedder will only\n",
    "        require a single tensor, because it is designed to run on the output of a\n",
    "        single TokenIndexer. For example, the ELMo Token Embedder can be used in\n",
    "        two modes, one of which requires both character ids and word ids for the\n",
    "        same text. Note that the list of token indexer names is `ordered`, meaning\n",
    "        that the tensors produced by the indexers will be passed to the embedders\n",
    "        in the order you specify in this list.\n",
    "    allow_unmatched_keys : ``bool``, optional (default = False)\n",
    "        If True, then don't enforce the keys of the ``text_field_input`` to\n",
    "        match those in ``token_embedders`` (useful if the mapping is specified\n",
    "        via ``embedder_to_indexer_map``).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 token_embedders: Dict[str, TokenEmbedder],\n",
    "                 embedder_to_indexer_map: Dict[str, List[str]] = None,\n",
    "                 allow_unmatched_keys: bool = False) -> None:\n",
    "        super(BasicTextFieldEmbedder, self).__init__()\n",
    "        self._token_embedders = token_embedders\n",
    "        self._embedder_to_indexer_map = embedder_to_indexer_map\n",
    "        for key, embedder in token_embedders.items():\n",
    "            name = 'token_embedder_%s' % key\n",
    "            self.add_module(name, embedder)\n",
    "        self._allow_unmatched_keys = allow_unmatched_keys\n",
    "\n",
    "    @overrides\n",
    "    def get_output_dim(self) -> int:\n",
    "        output_dim = 0\n",
    "        for embedder in self._token_embedders.values():\n",
    "            output_dim += embedder.get_output_dim()\n",
    "        return output_dim\n",
    "    \n",
    "    def augment(self, text_field_input: Dict[str, torch.Tensor], num_wrapping_dims: int=0):\n",
    "        pass\n",
    "\n",
    "    def forward(self, text_field_input: Dict[str, torch.Tensor], num_wrapping_dims: int = 0) -> torch.Tensor:\n",
    "        embedder_keys = self._token_embedders.keys()\n",
    "        input_keys = text_field_input.keys()\n",
    "\n",
    "        # Check for unmatched keys\n",
    "        if not self._allow_unmatched_keys:\n",
    "            if embedder_keys < input_keys:\n",
    "                # token embedder keys are a strict subset of text field input keys.\n",
    "                message = (f\"Your text field is generating more keys ({list(input_keys)}) \"\n",
    "                           f\"than you have token embedders ({list(embedder_keys)}. \"\n",
    "                           f\"If you are using a token embedder that requires multiple keys \"\n",
    "                           f\"(for example, the OpenAI Transformer embedder or the BERT embedder) \"\n",
    "                           f\"you need to add allow_unmatched_keys = True \"\n",
    "                           f\"(and likely an embedder_to_indexer_map) to your \"\n",
    "                           f\"BasicTextFieldEmbedder configuration. \"\n",
    "                           f\"Otherwise, you should check that there is a 1:1 embedding \"\n",
    "                           f\"between your token indexers and token embedders.\")\n",
    "                raise ConfigurationError(message)\n",
    "\n",
    "            elif self._token_embedders.keys() != text_field_input.keys():\n",
    "                # some other mismatch\n",
    "                message = \"Mismatched token keys: %s and %s\" % (str(self._token_embedders.keys()),\n",
    "                                                                str(text_field_input.keys()))\n",
    "                raise ConfigurationError(message)\n",
    "\n",
    "        embedded_representations = []\n",
    "        keys = sorted(embedder_keys)\n",
    "        for key in keys:\n",
    "            # If we pre-specified a mapping explictly, use that.\n",
    "            if self._embedder_to_indexer_map is not None:\n",
    "                tensors = [text_field_input[indexer_key] for\n",
    "                           indexer_key in self._embedder_to_indexer_map[key]]\n",
    "            else:\n",
    "                # otherwise, we assume the mapping between indexers and embedders\n",
    "                # is bijective and just use the key directly.\n",
    "                tensors = [text_field_input[key]]\n",
    "            # Note: need to use getattr here so that the pytorch voodoo\n",
    "            # with submodules works with multiple GPUs.\n",
    "            embedder = getattr(self, 'token_embedder_{}'.format(key))\n",
    "            for _ in range(num_wrapping_dims):\n",
    "                embedder = TimeDistributed(embedder)\n",
    "            token_vectors = embedder(*tensors)\n",
    "            embedded_representations.append(token_vectors)\n",
    "        return torch.cat(embedded_representations, dim=-1)\n",
    "\n",
    "    # This is some unusual logic, it needs a custom from_params.\n",
    "    @classmethod\n",
    "    def from_params(cls, vocab: Vocabulary, params: Params) -> 'BasicTextFieldEmbedder':  # type: ignore\n",
    "        # pylint: disable=arguments-differ,bad-super-call\n",
    "\n",
    "        # The original `from_params` for this class was designed in a way that didn't agree\n",
    "        # with the constructor. The constructor wants a 'token_embedders' parameter that is a\n",
    "        # `Dict[str, TokenEmbedder]`, but the original `from_params` implementation expected those\n",
    "        # key-value pairs to be top-level in the params object.\n",
    "        #\n",
    "        # This breaks our 'configuration wizard' and configuration checks. Hence, going forward,\n",
    "        # the params need a 'token_embedders' key so that they line up with what the constructor wants.\n",
    "        # For now, the old behavior is still supported, but produces a DeprecationWarning.\n",
    "\n",
    "        embedder_to_indexer_map = params.pop(\"embedder_to_indexer_map\", None)\n",
    "        if embedder_to_indexer_map is not None:\n",
    "            embedder_to_indexer_map = embedder_to_indexer_map.as_dict(quiet=True)\n",
    "        allow_unmatched_keys = params.pop_bool(\"allow_unmatched_keys\", False)\n",
    "\n",
    "        token_embedder_params = params.pop('token_embedders', None)\n",
    "\n",
    "        if token_embedder_params is not None:\n",
    "            # New way: explicitly specified, so use it.\n",
    "            token_embedders = {\n",
    "                    name: TokenEmbedder.from_params(subparams, vocab=vocab)\n",
    "                    for name, subparams in token_embedder_params.items()\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            # Warn that the original behavior is deprecated\n",
    "            warnings.warn(DeprecationWarning(\"the token embedders for BasicTextFieldEmbedder should now \"\n",
    "                                             \"be specified as a dict under the 'token_embedders' key, \"\n",
    "                                             \"not as top-level key-value pairs\"))\n",
    "\n",
    "            token_embedders = {}\n",
    "            keys = list(params.keys())\n",
    "            for key in keys:\n",
    "                embedder_params = params.pop(key)\n",
    "                token_embedders[key] = TokenEmbedder.from_params(vocab=vocab, params=embedder_params)\n",
    "\n",
    "        params.assert_empty(cls.__name__)\n",
    "        return cls(token_embedders, embedder_to_indexer_map, allow_unmatched_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "\n",
    "if config.model_type == \"standard\":\n",
    "    token_embedding = CustomEmbedding(num_embeddings=config.vocab_size + 5,\n",
    "                                      embedding_dim=config.embedding_dim,\n",
    "                                      weight=torch.tensor(embedding_weights, dtype=torch.float),\n",
    "                                      dropout=config.dropoute, padding_index=0)\n",
    "    word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "elif \"elmo\" in config.model_type:\n",
    "    from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "\n",
    "    options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "    weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "\n",
    "    elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "    word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})\n",
    "elif \"bert\" in config.model_type:\n",
    "    from allennlp.modules.token_embedders.bert_token_embedder import PretrainedBertEmbedder\n",
    "    bert_embedder = PretrainedBertEmbedder(\n",
    "             pretrained_model=config.model_type,\n",
    "             top_layer_only=True, # conserve memory\n",
    "    )\n",
    "    word_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": bert_embedder},\n",
    "                                                                 # we'll be ignoring masks so we'll need to set this to True\n",
    "                                                                allow_unmatched_keys = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"bert\" not in config.model_type:\n",
    "    encoder = BiGRUAttentionEncoder(\n",
    "            word_embeddings.get_output_dim(),\n",
    "            config.hidden_sz,\n",
    "        )\n",
    "else:\n",
    "    BERT_DIM = word_embeddings.get_output_dim()\n",
    "\n",
    "    class BertSentencePooler(Seq2VecEncoder):\n",
    "        def forward(self, embs: torch.tensor, \n",
    "                    mask: torch.tensor=None) -> torch.tensor:\n",
    "            # extract first token tensor\n",
    "            return embs[:, 0]\n",
    "\n",
    "        @overrides\n",
    "        def get_output_dim(self) -> int:\n",
    "            return BERT_DIM\n",
    "\n",
    "    encoder = BertSentencePooler(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(\n",
    "    word_embeddings, \n",
    "    encoder, \n",
    "    out_sz=config.n_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize bias according to prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.bias_init:\n",
    "    class_bias = torch.zeros(len(label_cols))\n",
    "    for i, _ in enumerate(label_cols):\n",
    "        p = train_labels[:, i].mean()\n",
    "        class_bias[i] = np.log(p / (1-p))\n",
    "\n",
    "    model.projection.bias.data = class_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: model.cuda()\n",
    "else: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch[\"tokens\"]\n",
    "labels = batch\n",
    "\n",
    "mask = get_text_field_mask(tokens) == 0\n",
    "embeddings = model.word_embeddings(tokens)\n",
    "state = model.encoder(embeddings, mask)\n",
    "class_logits = model.projection(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(**batch)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.grad for x in list(model.encoder.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"label\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"tokens\"][\"tokens\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randperm(batch[\"label\"].size(0))\n",
    "tokens1, tokens2 = batch[\"tokens\"], {\"tokens\": batch[\"tokens\"][\"tokens\"][p]}\n",
    "labels1, labels2 = batch[\"label\"], batch[\"label\"][p]\n",
    "mask1, mask2 = (get_text_field_mask(t) for t in (tokens1, tokens2))\n",
    "embs1, embs2 = (model.word_embeddings(t) for t in (tokens1, tokens2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = model.lambda_sampler.sample((mask.size(0), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate\n",
    "embs = ratios * embs1 + (1-ratios) * embs2\n",
    "label = ratios * labels1 + (1-ratios) * labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.mixup(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training import trainer as _trainer\n",
    "from allennlp.training.trainer import *\n",
    "import math\n",
    "logger = _trainer.logger\n",
    "\n",
    "N_BATCHES_PER_UPDATE = config.batch_size // config.computational_batch_size\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, mixup_ratio: float=0., **kwargs):\n",
    "        \"\"\"Applies mixup to mixup_ratio samples in each batch\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mixup_ratio = mixup_ratio\n",
    "        \n",
    "    @overrides\n",
    "    def batch_loss(self, batch: TensorDict, for_training=True) -> torch.Tensor:\n",
    "        batch = nn_util.move_to_device(batch, self._cuda_devices[0])\n",
    "        output_dict = self.model(**batch)\n",
    "        try:\n",
    "            loss = output_dict[\"loss\"]\n",
    "            if for_training:\n",
    "                loss += self.model.get_regularization_penalty()\n",
    "        except KeyError:\n",
    "            if for_training:\n",
    "                raise RuntimeError(\"The model you are trying to optimize does not contain a\"\n",
    "                                   \" 'loss' key in the output of model.forward(inputs).\")\n",
    "            return None\n",
    "        \n",
    "        # apply mixup loss\n",
    "        if for_training and self.mixup_ratio > 0.:\n",
    "            mixup_output_dict = self.model.mixup(**batch)\n",
    "            loss += mixup_output_dict[\"loss\"] * self.mixup_ratio\n",
    "        return loss\n",
    "        \n",
    "    @gpu_mem_restore\n",
    "    def _train_epoch(self, epoch: int) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Trains one epoch and returns metrics. Copied from source\n",
    "        \"\"\"\n",
    "        logger.info(\"Epoch %d/%d\", epoch, self._num_epochs - 1)\n",
    "        peak_cpu_usage = peak_memory_mb()\n",
    "        logger.info(f\"Peak CPU memory usage MB: {peak_cpu_usage}\")\n",
    "        gpu_usage = []\n",
    "        for gpu, memory in gpu_memory_mb().items():\n",
    "            gpu_usage.append((gpu, memory))\n",
    "            logger.info(f\"GPU {gpu} memory usage MB: {memory}\")\n",
    "\n",
    "        train_loss = 0.0\n",
    "        # Set the model to \"train\" mode.\n",
    "        self.model.train()\n",
    "\n",
    "        # Get tqdm for the training batches\n",
    "        train_generator = self.iterator(self.train_data,\n",
    "                                        num_epochs=1,\n",
    "                                        shuffle=self.shuffle)\n",
    "        num_training_batches = self.iterator.get_num_batches(self.train_data)\n",
    "        self._last_log = time.time()\n",
    "        last_save_time = time.time()\n",
    "\n",
    "        batches_this_epoch = 0\n",
    "        if self._batch_num_total is None:\n",
    "            self._batch_num_total = 0\n",
    "\n",
    "        if self._histogram_interval is not None:\n",
    "            histogram_parameters = set(self.model.get_parameters_for_histogram_tensorboard_logging())\n",
    "\n",
    "        logger.info(\"Training\")\n",
    "        train_generator_tqdm = Tqdm.tqdm(train_generator,\n",
    "                                         total=num_training_batches)\n",
    "        cumulative_batch_size = 0\n",
    "        for batch in train_generator_tqdm:\n",
    "            batches_this_epoch += 1\n",
    "            self._batch_num_total += 1\n",
    "            batch_num_total = self._batch_num_total\n",
    "\n",
    "            self._log_histograms_this_batch = self._histogram_interval is not None and (\n",
    "                    batch_num_total % self._histogram_interval == 0)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            ###########\n",
    "            # Custom  #\n",
    "            ###########\n",
    "            loss = self.batch_loss(batch, for_training=True)\n",
    "            if torch.isnan(loss):\n",
    "                raise ValueError(\"nan loss encountered\")\n",
    "            train_loss += loss.item()\n",
    "            # wait to update\n",
    "            if (batches_this_epoch % N_BATCHES_PER_UPDATE) != 0: continue\n",
    "            ###############\n",
    "            # End Custom  #\n",
    "            ###############\n",
    "            \n",
    "            loss.backward()\n",
    "            batch_grad_norm = self.rescale_gradients()\n",
    "            \n",
    "            ###########\n",
    "            # Custom  #\n",
    "            ###########\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if torch.isnan(param.data).any() or torch.isinf(param.data).any():\n",
    "                    raise ValueError(f\"Nan/Inf weights in param {name}: \\n {param}\")\n",
    "            ###############\n",
    "            # End Custom  #\n",
    "            ###############\n",
    "\n",
    "            # This does nothing if batch_num_total is None or you are using an\n",
    "            # LRScheduler which doesn't update per batch.\n",
    "            if self._learning_rate_scheduler:\n",
    "                self._learning_rate_scheduler.step_batch(batch_num_total)\n",
    "\n",
    "            if self._log_histograms_this_batch:\n",
    "                # get the magnitude of parameter updates for logging\n",
    "                # We need a copy of current parameters to compute magnitude of updates,\n",
    "                # and copy them to CPU so large models won't go OOM on the GPU.\n",
    "                param_updates = {name: param.detach().cpu().clone()\n",
    "                                 for name, param in self.model.named_parameters()}\n",
    "                self.optimizer.step()\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    param_updates[name].sub_(param.detach().cpu())\n",
    "                    update_norm = torch.norm(param_updates[name].view(-1, ))\n",
    "                    param_norm = torch.norm(param.view(-1, )).cpu()\n",
    "                    self._tensorboard.add_train_scalar(\"gradient_update/\" + name,\n",
    "                                                       update_norm / (param_norm + 1e-7),\n",
    "                                                       batch_num_total)\n",
    "            else:\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Update the description with the latest metrics\n",
    "            metrics = self._get_metrics(train_loss, batches_this_epoch)\n",
    "            description = self._description_from_metrics(metrics)\n",
    "\n",
    "            train_generator_tqdm.set_description(description, refresh=False)\n",
    "\n",
    "            # Log parameter values to Tensorboard\n",
    "            if batch_num_total % self._summary_interval == 0:\n",
    "                if self._should_log_parameter_statistics:\n",
    "                    self._parameter_and_gradient_statistics_to_tensorboard(batch_num_total, batch_grad_norm)\n",
    "                if self._should_log_learning_rate:\n",
    "                    self._learning_rates_to_tensorboard(batch_num_total)\n",
    "                self._tensorboard.add_train_scalar(\"loss/loss_train\", metrics[\"loss\"], batch_num_total)\n",
    "                self._metrics_to_tensorboard(batch_num_total,\n",
    "                                             {\"epoch_metrics/\" + k: v for k, v in metrics.items()})\n",
    "\n",
    "            if self._log_histograms_this_batch:\n",
    "                self._histograms_to_tensorboard(batch_num_total, histogram_parameters)\n",
    "\n",
    "            if self._log_batch_size_period:\n",
    "                cur_batch = self._get_batch_size(batch)\n",
    "                cumulative_batch_size += cur_batch\n",
    "                if (batches_this_epoch - 1) % self._log_batch_size_period == 0:\n",
    "                    average = cumulative_batch_size/batches_this_epoch\n",
    "                    logger.info(f\"current batch size: {cur_batch} mean batch size: {average}\")\n",
    "                    self._tensorboard.add_train_scalar(\"current_batch_size\", cur_batch, batch_num_total)\n",
    "                    self._tensorboard.add_train_scalar(\"mean_batch_size\", average, batch_num_total)\n",
    "\n",
    "            # Save model if needed.\n",
    "            if self._model_save_interval is not None and (\n",
    "                    time.time() - last_save_time > self._model_save_interval\n",
    "            ):\n",
    "                last_save_time = time.time()\n",
    "                self._save_checkpoint(\n",
    "                        '{0}.{1}'.format(epoch, time_to_str(int(last_save_time))), [], is_best=False\n",
    "                )\n",
    "        metrics = self._get_metrics(train_loss, batches_this_epoch, reset=True)\n",
    "        metrics['cpu_memory_MB'] = peak_cpu_usage\n",
    "        for (gpu_num, memory) in gpu_usage:\n",
    "            metrics['gpu_'+str(gpu_num)+'_memory_MB'] = memory\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_options = {\n",
    "    # TODO: Add appropriate learning rate scheduler\n",
    "    \"should_log_parameter_statistics\": True,\n",
    "    \"should_log_learning_rate\": True,\n",
    "    \"num_epochs\": config.epochs,\n",
    "    \"mixup_ratio\": config.mixup_ratio,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.environ[\"IS_COLAB\"] != \"True\" and not config.testing):\n",
    "    SER_DIR = DATA_ROOT / \"ckpts\" / RUN_ID\n",
    "else:\n",
    "    SER_DIR = None\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds + train_aug_ds if config.use_augmented else train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    serialization_dir=SER_DIR,\n",
    "    cuda_device=0 if USE_GPU else -1,\n",
    "    **training_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from collections import defaultdict\n",
    "\n",
    "def dict_append(d: Dict[str, List], upd: Dict[str, Any]) -> Dict[str, List]:\n",
    "    for k, v in upd.items(): d[k].append(v)\n",
    "\n",
    "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
    "        \n",
    "class Predictor:\n",
    "    def __init__(self, model: Model, iterator: DataIterator,\n",
    "                 cuda_device: int=-1) -> None:\n",
    "        self.model = model\n",
    "        self.iterator = iterator\n",
    "        self.cuda_device = cuda_device\n",
    "        \n",
    "    def _extract_data(self, batch) -> Dict[str, np.ndarray]:\n",
    "        out_dict = self.model(**batch)\n",
    "        lens = tonp(get_text_field_mask(batch[\"tokens\"]).sum(1))\n",
    "        return {\n",
    "                \"preds\": expit(tonp(out_dict[\"class_logits\"])),\n",
    "                \"oov_ratio\": tonp((batch[\"tokens\"][\"tokens\"] == 1).sum(1)) / lens,\n",
    "                \"lens\": lens,\n",
    "               }\n",
    "        \n",
    "    def _postprocess(self, predictions: Dict[str, np.ndarray]) -> np.ndarray:\n",
    "        return {k: np.concatenate(v, axis=0) for k, v in predictions.items()}\n",
    "    \n",
    "    @gpu_mem_restore\n",
    "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
    "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
    "        self.model.eval()\n",
    "        pred_generator_tqdm = Tqdm.tqdm(pred_generator,\n",
    "                                        total=self.iterator.get_num_batches(ds))\n",
    "        preds = defaultdict(list)\n",
    "        with torch.no_grad():\n",
    "            for batch in pred_generator_tqdm:\n",
    "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
    "                dict_append(preds, self._extract_data(batch))\n",
    "        return self._postprocess(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BasicIterator\n",
    "seq_iterator = BasicIterator(batch_size=64)\n",
    "seq_iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
    "train_meta = predictor.predict(train_ds) \n",
    "train_preds = train_meta.pop(\"preds\")\n",
    "test_meta = predictor.predict(test_ds)\n",
    "test_preds = test_meta.pop(\"preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv(DATA_ROOT / \"test_proced.csv\")[label_cols].values\n",
    "if config.testing:\n",
    "    test_labels = test_labels[:len(test_ds), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, thres=0.5):\n",
    "        if isinstance(thres, float):\n",
    "            self.thres = np.ones(len(label_cols)) * thres\n",
    "        else:\n",
    "            self.thres = thres\n",
    "    \n",
    "    def _to_metric_dict(self, t: np.ndarray, y: np.ndarray, thres: float) -> Dict:\n",
    "        tn, fp, fn, tp = confusion_matrix(t, y >= thres).ravel()\n",
    "        return {\"auc\": roc_auc_score(t, y),\n",
    "                \"f1\": f1_score(t, y >= thres),\n",
    "                \"acc\": accuracy_score(t, y >= thres),\n",
    "                \"tnr\": tn / len(t), \"fpr\": fp / len(t),\n",
    "                \"fnr\": fn / len(t), \"tpr\": tp / len(t),\n",
    "                \"precision\": tp / (tp + fp), \"recall\": tp / (tp + fn),\n",
    "        }\n",
    "\n",
    "    def _stats_per_quadrant(self, tgt, preds, metadata: Dict[str, np.ndarray]):\n",
    "        out_data = {}\n",
    "        for i, lbl in enumerate(label_cols):\n",
    "            # get indicies of each quadrant`\n",
    "            preds_bin = preds[:, i] >= self.thres[i]\n",
    "            quads = {\n",
    "                \"tp\": np.where((tgt[:, i] == 1) & preds_bin)[0],\n",
    "                \"fp\": np.where((tgt[:, i] == 0) & preds_bin)[0],\n",
    "                \"tn\": np.where((tgt[:, i] == 0) & ~preds_bin)[0],\n",
    "                \"fn\": np.where((tgt[:, i] == 1) & ~preds_bin)[0],\n",
    "            }\n",
    "            # get stats for metadata\n",
    "            out_data[lbl] = {}\n",
    "            for q, qidxs in quads.items():\n",
    "                out_data[lbl][q] = {}\n",
    "                for k, full_data in metadata.items():\n",
    "                    data = full_data[qidxs]\n",
    "                    if len(data) > 0:\n",
    "                        out_data[lbl][q][f\"{k}_mean\"] = data.mean()\n",
    "                        out_data[lbl][q][f\"{k}_std\"] = data.std()\n",
    "                        out_data[lbl][q][f\"{k}_min\"] = data.min()\n",
    "                        out_data[lbl][q][f\"{k}_max\"] = data.max()\n",
    "                    else:\n",
    "                        out_data[lbl][q][f\"{k}_mean\"] = np.nan\n",
    "                        out_data[lbl][q][f\"{k}_std\"] = np.nan\n",
    "                        out_data[lbl][q][f\"{k}_min\"] = np.nan\n",
    "                        out_data[lbl][q][f\"{k}_max\"] = np.nan\n",
    "        return out_data\n",
    "    \n",
    "    @gpu_mem_restore\n",
    "    def evaluate(self, tgt: np.ndarray, preds: np.ndarray,\n",
    "                 trn_tgt: np.ndarray, trn_preds: np.ndarray,\n",
    "                 metadata: Dict[str, np.ndarray]={}) -> Dict:\n",
    "        \"\"\"\n",
    "        Metadata: Data about the inputs (e.g. length, OOV ratio)\n",
    "        \"\"\"\n",
    "        train_label_metrics = {}\n",
    "        label_metrics = {}\n",
    "                \n",
    "        # get per-label stats\n",
    "        for i, lbl in enumerate(label_cols):\n",
    "            train_label_metrics[lbl] = self._to_metric_dict(trn_tgt[:, i],\n",
    "                                                            trn_preds[:, i],\n",
    "                                                            self.thres[i])\n",
    "            label_metrics[lbl] = self._to_metric_dict(tgt[:, i], preds[:, i],\n",
    "                                                      self.thres[i])\n",
    "            print(f\"========{lbl}=========\")\n",
    "            print(label_metrics[lbl])\n",
    "        \n",
    "        # get global stats\n",
    "        label_metrics[\"global\"] = {}\n",
    "        for mtrc in label_metrics[\"toxic\"].keys():\n",
    "            label_metrics[\"global\"][mtrc] = \\\n",
    "                np.mean([label_metrics[col][mtrc] for col in label_cols])\n",
    "            \n",
    "        # get per-label-quadrant stats\n",
    "        quad_stats = self._stats_per_quadrant(tgt, preds, metadata)\n",
    "        if len(quad_stats) > 0:\n",
    "            for c in label_cols:\n",
    "                label_metrics[c][\"quad_stats\"] = quad_stats[c]\n",
    "\n",
    "        metrics = {\n",
    "            \"train\": train_label_metrics,\n",
    "            \"test\": label_metrics,\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute best threshold based on training data\n",
    "thres = np.zeros(len(label_cols))\n",
    "for i, col in enumerate(label_cols):\n",
    "    best_score = -1\n",
    "    best_thres = -1\n",
    "    for x in np.linspace(0, 1.0, num=99):\n",
    "        scr = f1_score(train_labels[:, i], train_preds[:, i] > x)\n",
    "        if scr > best_score:\n",
    "            best_thres = x\n",
    "            best_score = scr\n",
    "    thres[i] = best_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(thres=thres)\n",
    "label_metrics = evaluator.evaluate(\n",
    "    test_labels, test_preds,\n",
    "    train_labels, train_preds,\n",
    "    metadata=test_meta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record results and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ[\"IS_COLAB\"] != \"True\":\n",
    "    import sys\n",
    "    sys.path.append(\"../lib\")\n",
    "    from record_experiments import record\n",
    "else:\n",
    "    PASSWORD = \"foobar\" # FILL IN IF COLAB\n",
    "\n",
    "    from typing import *\n",
    "    import pymongo\n",
    "    from bson.objectid import ObjectId\n",
    "    import os\n",
    "    import logging\n",
    "\n",
    "    # Logger\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('[%(levelname)s] %(asctime)s - %(name)s %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    conn_str = f\"mongodb+srv://root:{PASSWORD}@cluster0-ptgoc.mongodb.net/test?retryWrites=true\"\n",
    "\n",
    "    client = pymongo.MongoClient(conn_str)\n",
    "    db = client.experiments\n",
    "    collection = db.logs\n",
    "\n",
    "    def record(log: dict):\n",
    "        res = collection.insert_one(log)\n",
    "        logger.info(f\"Inserted results at id {res.inserted_id}\")\n",
    "        return res\n",
    "\n",
    "    def find(id_: Optional[str]=None, query: Optional[dict]=None):\n",
    "        if query is None: query = {\"_id\": ObjectId(id_)}\n",
    "        res = collection.find_one(query)\n",
    "        return res\n",
    "\n",
    "    def delete(id_: Optional[str]=None, query: Optional[dict]=None):\n",
    "        if query is None: query = {\"_id\": ObjectId(id_)}\n",
    "        res = collection.delete_many(query)\n",
    "        logger.info(f\"Deleted {res.deleted_count} entries\")\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "if not config.testing:\n",
    "    experiment_log = dict(config)\n",
    "    tz = timezone('EST')\n",
    "    experiment_log[\"execution_date\"] = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M %Z\")\n",
    "    experiment_log.update(metrics)\n",
    "    experiment_log.update(label_metrics)\n",
    "    record(experiment_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
